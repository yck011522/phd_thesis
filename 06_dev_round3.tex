\chapter[Exploration Round 3 - Automatic Clamp Placement]{Exploration Round 3\\Automatic Clamp Placement}
\label{chapter:exploration-round-3}

\section{Goal}
\label{section:exploration-3-goal}

The goal of the third round is to address the issues observed in the previous round and to test the rest of the automatic process that were not included in the previous round \seeref{subsection:exploration-1-dirt-clamping-assembly-process-task-list-v1}.
% \todo{The following sentence revised to explain that the BusStop is reconstructed}No new demonstrator structure was created for this round because the BusStop Pavilion can be reused again for testing the missing robotic tasks. The following list shows an overview of the technical development in this round to achieve the goal.

\begin{itemize}
	\item \textbf{Mechatronics}
    \begin{itemize}[nosep]
	   \item Implemented docking adapter
	   \item Addressed issues found in clamp drive electronics
    \end{itemize}

	\item \textbf{Controller / Firmware}
    \begin{itemize}[nosep]
    	\item Added stall protection in motion control
    	\item Process Execution Controller switched from GH interface to standalone GUI application
    \end{itemize}

	\item \textbf{CAD Design Software}
    \begin{itemize}[nosep]
    	\item Design software switched to Rhino Python
    \end{itemize}

    \item \textbf{Task and Motion Planning }(TAMP)
    \begin{itemize}[nosep]
    	\item Developed Flowchart Formulation method for task planning
    	\item Established high-level and low-level tasks and planning template
    	\item Developed planning method to handle Taught configuration
    	\item Developed Non-Sequential Multimodal Motion Planning (MMMP) solver
    	\item Developed Kinematic Robotic Tool Models
    	\item Integrated Post-planning Trajectory Smoothing
    \end{itemize}

\end{itemize}

The main development effort in this round was to develop the software infrastructure that would allow automatic Task and Motion Planning (TAMP). Many of the related developments and discoveries presented in this chapter were created in collaboration with YiJiang Huang (from MIT Architecture) who specialises in TAMP for Construction Tasks. The level of software automation would not have been possible without this collaboration.

\subsection{DiRT Clamping Assembly Process Task List (Version 2)}
\label{subsection:exploration-3-dirt-clamping-assembly-process-task-list-v2}

The robotic process task list is a revision from \noseeref{subsection:exploration-1-dirt-clamping-assembly-process-task-list-v1} after incorporating the lessons learned about narrow passages \seeref{subsection:exploration-2-narrow-passage-problem}. Approach and Retract targets are added to the beginning or the end of Free Motions to circumvent the Narrow Passage problems. However, this added many small motions to the overall task list.

In order to maintain a high level overview of the process, I developed a task group concept that is able to represent a group of tasks in an abstract way. This is referred to as \textbf{High-Level Tasks}. For example, it can contain a free motion to go to a target, linear motions between approach and retract points, and tool operations such as gripper movements and clamp movements.

Table Figure \ref{table:high-level-task-v2} shows the High-Level Tasks, the Low-Level Tasks are described later \seeref{subsubsection:exploration-3-expanding-task-groups}.

\begin{table}[!h]
    \includegraphics[page=1, trim=25.4mm 130mm 25.4mm 33mm, clip, width=0.98\textwidth]{tables/Tables in Chapter 6.pdf}
    \caption{High-Level Tasks for DiRT Clamping Assembly Process (Version 2)}
    \label{table:high-level-task-v2}
\end{table}

\FloatBarrier

\subsection{Workflow for Generating Assembly Programmes}
\label{subsection:exploration-3-workflow-for-generating-assembly-programmes}

\todo{This section used to be located in the Background, as pointed out my Matthias in the Google Doc comment, I have moved it into this goal section. I think it fits better here.}
In this thesis, the generation of robotic assembly programmes is hypothesised to be similar to the generation of machining processes. Both of them require the creation of robotic trajectories (analogous to toolpaths) while satisfying a list of machine constraints (e.g. avoiding collisions). Therefore, the development in this thesis follows a similar workflow to that of CAM software for machining for testing this hypothesis.

Existing CAM software for machining follows a structured workflow that typically begins with importing a CAD model containing the geometry of the part to be machined. A Computer Numeric Control (CNC) programmer (also known as machinist, engineer, technician) then defines the CNC machine’s kinematics, stock material setup, fixture geometry (collision geometry) and tools. The CAM software then analyses the geometry and generates a series of toolpaths for each operation while considering the machine and the tool setup's constraints, such as spindle speed, feed rate, and tool engagement. After generating the toolpaths, the programmer reviews the simulation results and makes adjustments if needed. Once the tool paths are satisfactory, the CAM software creates G-code instructions, which are sent to the CNC machine for execution.

In comparison, the workflow for generating robotic assembly programmes can also start with the Assembly Model \seeref{subsection:exploration-2-assembly-model-data-structure-and-functions} containing the geometry and design information of the timber structure. A production engineer\footnote{ The title of this persona is has no precedence. I name it the ‘Production Engineer’ to avoid confusion with existing ‘construction planner’ that plans construction site or ‘programmer’ that writes software.} then defines the setup of the robotic environment, and makes decisions about which tools to use and what assembly strategy to use. A software then generates the assembly programme, considering factors such as assembly sequence, robot kinematics, joint assembly tools and collisions. Similar to CAM machining workflows, the generated programme is reviewed and adjusted as needed before being sent to the robotic system for execution.

Despite the similarities between generating robotic assembly programmes and CAM machining programmes, there are notable differences. \todo{rephased the following two sentence.}Assembly operations focus on the manipulation and joining of components rather than material removal in machining. In fact, the discrete components are often shaped by machining processes beforehand. Additionally, robotic assembly processes have more complex constraints \parencite{wangStateArtComputational2021}. While CAM software for machining has reached a high level of automation and optimization, software for generating robotic assembly programmes has not yet achieved the same maturity, partly due to the recent adoption of robotics for spatial construction tasks. Challenges in generating robotic assembly programmes include accurately modelling and simulating the assembly process, accounting for factors like assembly tools, joint connections, and structural stability. Furthermore, the software must generate efficient and feasible assembly sequences, considering accessibility, reachability, and potential collisions.

This thesis aims to address these challenges by developing and testing workflows that are inspired by CAM machining. The goal is to create an efficient fabrication-aware design process that extends to the robotic assembly constraints. By adopting the patterns established for CAM machining workflows, the development process can avoid reinventing the wheel while addressing the unique challenges of robotic assembly in timber construction.

\vspace{2\baselineskip}

\FloatBarrier

\section{Background}
\label{section:exploration-3-background}

\subsection{Multimodal Motion Planning (MMMP)}
\label{subsection:exploration-3-multimodal-motion-planning-mmmp}

In the previous exploration round, motion planning was introduced as finding the path between two targets. In order to find the trajectory for a complete robotic process, it is necessary to consider many more robotic motions at the same time. Specifically, the robotic motions listed in \noseeref{subsection:exploration-3-dirt-clamping-assembly-process-task-list-v2} have to be chained together such that their starting and ending configuration are continuous. In addition, the manually performed backtracking in the last round would have to be automated to handle this many more chained motions \seeref{subsubsection:exploration-2-motion-planning}.

Multimodal Motion Planning (MMMP) is an advanced approach to robotic motion planning that takes into consideration different kinematic configurations, different motion constraints and different types of actuators \parencite{hauserMultimodalMotionPlanning2010, hauserRandomizedMultimodalMotion2011}. MMMP expands the capabilities of single-query motion planning algorithms \seeref{subsubsection:exploration-2-selecting-motion-planning-algorithms} to perform more complex tasks.

MMMP incorporats the concept of multiple \textit{modes} into the planning process, enabling the robot to switch between different operational modes as needed to achieve the desired task more efficiently. The modes that are relevant to the DiRT Assembly Process includes the following components:

\begin{itemize}
	\item \textbf{Kinematic chain configuration --} The attached objects after the kinematic chain of the robot, such as docking adapter, clamps, grippers and beams.
	\item \textbf{Kinematic tool geometry --} Position of the clamp jaw and gripper fingers depending on whether they are open or close.
	\item \textbf{ACM --} Objects that are allowed to collide when they perform a certain part of the operation, such as joint closure.
	\item \textbf{Motion Type --} Linear vs Free motion
\end{itemize}

The mode definition allows the planner to understand the difference between different planning requirements in different parts of the operation. The MMMP solver used in this thesis was developed in collaboration with YiJiang Huang. The solver is described in the later development sections \seerefii{subsubsection:exploration-3-multimodal-motion-planning-mmmp-solver}{subsection:exploration-3-non-sequential-planning-order} and in YiJiang’s PhD dissertation \parencite{huangAlgorithmicPlanningRobotic2022}.

\subsection{Robot Targets -Taught Configuration and Cartesian Pose}
\label{subsection:exploration-3-robot-targets-taught-configuration-and-cartesian-pose}

In order to specify the motion of a robotic arm, a program must be created. This is often achieved by a symbolic programme, written in a manufacturer-specific language such as Rapid for ABB robots and KRL for Kuka robots. The programme would contain a number of targets which the robot can pass through or stop at. These targets can be specified as \textbf{Robot Configurations}, a list of position values corresponding to each robot joint, or \textbf{Cartesian Poses}, a 6 DOF position and orientation definition.

For industrial automation with repetitive targets, the targets are typically specified by configurations. These would be created by the production engineer or programmer using a joystick to jog the arm to the intended target and record the joint values at that moment. This process is referred to as ‘teaching’. Teaching has to be performed in the production environment using the real robot, with tools and workpieces attached to the robot to accommodate deflection due to payload. The recorded configurations are known as \textbf{Taught Configurations}. If accurate alignment is needed, the jogging can be performed in small increments until good alignment is confirmed. This has to be repeated for every key position where alignment is important.

Industrial robotic arms typically have good repeatability, meaning it is capable to go back to this taught target under the same payload. For performing repetitive tasks, this is largely sufficient. However, it is important to note that repeatability is different from ‘accuracy’, which is a measurement of its ability to reach an uncalibrated target and under arbitary payload.

In cases where the target is not in a fixed position (e.g. position of an object located by a camera), or if the targets cannot be calibrated one by one, it is useful to specify them using a Cartesian Pose. This pose is often extracted from a digital model that estimates where the targets should be in relation to the robot base. The configuration of the robot joints must therefore be calculated using Inverse Kinematics (IK) calculation.

\todo{The following paragraph is revised to explain what I mean by stretched. I also mentioned that the RFL robot is one of those high DOF robot that is affected by the choice of configuration}The accuracy of the robot resulting from an IK calculation depends on the accuracy of the robot kinematics model, payload and the choice of configuration used to reach the pose. High-DOF robots, such as the RFL robotic platform, can have many different IK solutions that can reach the same target. If an IK result is choosen where the robotic arm's base is positioned far away from the payload (e.g. to avoid obstacles), the robotic arm will have to stretch its forearm (link 3 to 6) far away. This can result in more defection compared to another configuration that is closer to the robot base.

\FloatBarrier

\section{Development}
\label{section:exploration-3-development}

\subsection{Ground Platform Redesign}
\label{subsection:exploration-3-ground-platform-redesign}

In order to reduce the planning difficulty caused by the side-way connection between the columns and the ground platform \seeref{subsection:exploration-2-ground-platform-constraining-process-design}, a new platform was designed to allow the BusStop Pavilion to sit on top of two 50mm x 100mm aluminium profile that was laid horizontally. Figure \ref{fig:platform-redesign} shows the BusStop pavilion on the new platform. Two rows of vertical columns can be seen sitting flush with two aluminium profiles. The three tilted columns are supported by adding scaffolding manually after they are assembled.

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.99\textwidth]{images/6a/img01.jpg}
    \caption{Redesigned Ground Platform for BusStop Pavilion}
    \label{fig:platform-redesign}
\end{figure}


The constructed ground platform was measured with the iGPS system and adjusted until it was horizontally flat. The positions of the two horizontal aluminium profiles were precisely measured and added to the CAD model. This allowed later observation using the aluminium profiles as a datum to determine the correctness of the robotic timber placement. During execution, this proved to be invaluable for debugging the system inaccuracy \seeref{subsection:exploration-3-beam-placement-misalignment}.

\subsection{Tool Storage Pads}
\label{subsection:exploration-3-tool-storage-pads}

Storage pads were designed for keeping the gripper and clamps at a repeatable location for the robot to pick them up. Figure \ref{fig:tool-in-storage-pad} shows a CL3 Clamp and a PG500 Parallel Gripper placed in their storage pads during a test.

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.99\textwidth]{images/6a/img02.jpg}
    \caption{A Gripper and a Clamp in their Storage Pads}
    \label{fig:tool-in-storage-pad}
\end{figure}



The design of the clamp pad simulates the same attachment orientation when the clamps are attached to a beam (Figure \ref{fig:cl3-clamp-storage-pad}, left). However, this orientation was found to be difficult for teaching the robot (Figure \ref{fig:about-to-pick-up-clamp}, right). The two step movement needed to pick up the clamp (to clear the pins on the hanging gripper) was also found to be unnecessary. This design was modified in the next demonstrator to a straight pick up design.

% 2 Horizontal Image
\begin{figure}[!h]
    \centering
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/6a/img03.jpg}
        \caption{CL3 Clamp Storage Pad}
        \label{fig:cl3-clamp-storage-pad}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/6a/img04.jpg}
        \caption{Robot about to pick up clamp}
        \label{fig:about-to-pick-up-clamp}
    \end{subfigure}
    \caption{Photos showing the tilted pose when the clamp is picked up from the storage pad.}
    %\label{fig:uniquefigurelabel}
\end{figure}

\subsection{Robot Cable Guides}
\label{subsection:exploration-3-robot-cable-guides}

The robotic cable guides were designed to address the cable tangling problem found in the last round \seeref{subsection:exploration-2-robot-cables-problems}. Specifically, to avoid unconstrained cables tangling with the Partially Assembled (PA) structure or being pinched between the spherical wrist.

It is worth noting that the cable tangling problem is not new in the field of industrial robot operations. However, the robots used in manufacturing automation often perform repetitive motions and therefore, their cable guides can be designed to move in a predetermined manner. Moreover, they could be tested vigorously within a reasonable amount of time. In the context of architectural automation, the non-repetitive targets would require a cable guiding solution that can accommodate the whole range of motions that results from the motion planner. As the robotic arm contains 6 rotary joints, the cable can easily move in an unpredictable way.

The solution developed for this round, is to use cable guides to constrain the cables to move in a known location. Those locations can therefore be blocked by collision models during motion planning to avoid collision. The framework for designing the cable guides was to decouple the six rotary joints such that the cable guides can deal with one or two joints at a time.

The newly developed system established three groups for the robot:

\begin{description}[] % Environment provided enumitem package
% \begin{description}[style=unboxed] % Environment provided enumitem package
	\item [Joint 1 to 3] The base and upper arms. The cable slack in this area did not cause problems previously.
	\item [Joint 4] Forearm in-line joint where cable slack was more prominent and are often closest to the structure.
	\item [Joint 5 and 6] Wrist joints where pinching was a problem.
\end{description}

This new system developed for this test covered Joint 4 to 6, where the tangling problem was most severe in the previous round. This is because the range of motions in these three joints required a lot of extra cable slack to accommodate their movements.

\paragraph{Construction}

There are three mechanical parts that contribute to this system. The first is a \textbf{cable retraction system} (TR.RSE.02.40.R by Igus) combined with a flexible cable chain (TRE-40-058-0-B by Igus) with an external diameter of 43mm. The maximum retraction amount is 500mm chain length. Figure \ref{fig:cable-retraction-system} shows the retraction system mounted on the robot elbow, before Joint 4, and extended towards the wrist.

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.99\textwidth]{images/6a/img05.jpg}
    \caption{Cable retraction system mounted on the robot elbow}
    \label{fig:cable-retraction-system}
\end{figure}

Figure \ref{fig:swivel-cable-guide} shows the second part of the constraint, a \textbf{swivel cable guide} mounted on the side of the wrist. This guide is custom made with a 3D printer using PLA plastic and included a ball bearing to allow swivel movement.

Note that the free-moving segment between the retraction system and the swivel guide only have one rotational joint (Joint 4). This means that the cable chain would wrap around the forearm in a predictable manner.

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.99\textwidth]{images/6a/img06.jpg}
    \caption{Swivel cable guide mounted on the side of the wrist}
    \label{fig:swivel-cable-guide}
\end{figure}

The final segment bridges over Joint 5 and 6 and is connected to the tool changer. A 3D-printed mounting piece (Figure \ref{fig:3d-printed-mounting-piece}) is used to create an interface between the cable chain and one of the attachment flanges on the Schunk tool changer. The tangential entry of the cable chain to the tool changer prevents cable pinching even when Joint 5 is in a fully deflected position (Figure \ref{fig:cable-chain-in-stretched-pose}).

The combined effect of the retraction system pulling the cable chain, the swivel guide and the tangential layout allows the cable chain to move freely in almost all configurations. During the motion planning process, the joint range were limited to the following configurations (Joint 1 to 6):

{\footnotesize rm\_limits $=$ [(-175, 175), (-85, 145), (-175, 70), (-181, 181), (-120, 120), (-181, 181)]}

% 2 Horizontal Image
\begin{figure}[!h]
    \centering
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/6a/img07.jpg}
        \caption{3D-printed mounting interface}
        \label{fig:3d-printed-mounting-piece}
    \end{subfigure}
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/6a/img08.jpg}
        \caption{Cable chain in a fully stretched pose}
        \label{fig:cable-chain-in-stretched-pose}
    \end{subfigure}
    \hfill
    \caption{Details of the cable chain attachment to the tool changer with a tangential entry to avoid pinching}
    %\label{fig:uniquefigurelabel}
\end{figure}



\paragraph{Collision Model}

Figure \ref{fig:collision-mesh-of-the-tool-changer} shows the collision mesh (yellow) of the tool changer used for motion planning. Note that it covers a portion of volume where the cable chain leads out tangentially. Figure \ref{fig:collision-mesh-of-the-forearm} shows the collision meshes of the forearm. Extra boxes (orange) can be seen covering the swivel guide location and the location where the cable chain would pass over the wrist.

% 2 Horizontal Image
\begin{figure}[!h]
    \centering
    \begin{minipage}{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/6a/img09.jpg}
        \caption{Collision mesh of the tool changer}
        \label{fig:collision-mesh-of-the-tool-changer}
    \end{minipage}
    \hfill
    \begin{minipage}{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/6a/img10.jpg}
        \caption{Collision mesh of the forearm}
        \label{fig:collision-mesh-of-the-forearm}
    \end{minipage}
    %\label{fig:uniquefigurelabel}
\end{figure}

\paragraph{Lessons Learnt}

One note regarding the \textbf{cable retraction length}. It was only after the implementation that the retraction length appears to be an issue. The combined motion range of Joint 4, 5 and 6 requires a larger retractable cable range than expected. The 500mm retraction range offered by the default Igus system is not sufficient. Extra slack sometimes remained in the system depending on the configuration. Figure \ref{fig:cable-chain-in-a-very-loose-state} shows the chain in a very loose state, this image was taken before the wrist swivel guide is installed. The situation improved slightly after it was installed. Note that for future implementation, a retraction length of 800mm to 1m is more appropriate.

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.99\textwidth]{images/6a/img11.jpg}
    \caption{Cable chain in a very loose state}
    \label{fig:cable-chain-in-a-very-loose-state}
\end{figure}


\subsection{Design Software Implementation in Rhino Python}
\label{subsection:exploration-3-design-software-implementation-in-rhino-python}

The design software was upgraded from the previous Rhino (RH) Grasshopper (GH) implementation \seeref{subsection:exploration-2-difficulty-in-interactive-modelling} into a Python implementation within RH.

The main motivation is to depart from the GH functional programming paradigm, which automatically recomputes every downstream operation in the event of a data change. While this is a nice feature for ensuring all data is up to date, it also prevents any user interaction beyond changing the initial input. In addition, the full recomputation of every operation is slow and in many cases redundant.

The development to address this is a \textbf{model-based programming approach} that is focused on the creation and maintenance of a \textbf{Model}. Once created, this model can be revisited and edited. Figure \ref{fig:functional-programming-approach} shows the difference between (a) a functional programming paradigm and (b) a model-based approach.

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.99\textwidth]{images/6a/interactive_1.pdf}
    \caption{Difference between functional programming and model-based approach}
    \label{fig:functional-programming-approach}
\end{figure}


Figure \ref{fig:interactive-assembly-modelling-functions} shows an example of some interactive assembly modelling functions that can benefit from the model-based approach. For example, the user can work between:

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.99\textwidth]{images/6a/interactive_2.pdf}
    \caption{Interactive Assembly Modelling Functions}
    \label{fig:interactive-assembly-modelling-functions}
\end{figure}


\begin{itemize}
	\item (a) and (b) to change the beam arrangements
	\item (c) to resolve assembly direction problems
\end{itemize}

By updating only part of the model where it is necessary, the user decisions that were provided earlier can be kept. Note that it is not impossible but very difficult to achieve this with a GH script and its interface. By switching to Rhino Python, a different script can be used to handle each user interaction, and contain the intelligence on which part of the model needs updating.

Figure \ref{fig:editing-the-assembly-model} shows the UI for editing the \textbf{assembly model}; commands such as \codett{AddBeam}, \codett{MoveAssembly}, and \codett{FlipBeamAssemblyDirection} are shown in Rhino command line. Figure \ref{fig:editing-the-assembly-sequence} shows the UI for editing the \textbf{assembly sequence}; commands such as \codett{MoveEarlier}, \codett{MoveLater}, \codett{PickElementToGoAfterThis}, and \\ \codett{ChangeAssemblyMethod} are shown. In practice, I have found that the command\\ \codett{FlipBeamAssemblyDirection} is also helpful while editing the sequence.

% 2 Horizontal Image
\begin{figure}[!h]
    \centering
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/6a/img14.jpg}
        \caption{Editing the assembly model}
        \label{fig:editing-the-assembly-model}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/6a/img15.jpg}
        \caption{Editing the assembly sequence}
        \label{fig:editing-the-assembly-sequence}
    \end{subfigure}
    \caption{User Interface for Editing the Assembly Model and Assembly Sequence}
    \label{fig:user-interface-for-editing}
\end{figure}


While there was no need to recreate the BusStop Assembly Model for this Exploration Round, the newly developed process design workflow \seeref{subsection:exploration-3-process-design-workflow} benefited greatly from this improvement. The visualisation and interactive UI for process design is also accessible from the toolbar in Rhino. More screen capture can be found in the later sections \seeref{subsubsection:exploration-3-process-visualization-and-adjustment}.

\subsection{Process Design Workflow}
\label{subsection:exploration-3-process-design-workflow}

The process design workflow is a downstream operation after the Assembly Model is completed. In this thesis, it is conceived to be a human-in-the-loop workflow where a production engineer is present to bridge the gap between design and production. However, the thesis aims to study to what extent this step can be automated.

Because decisions made in this stage do not affect architectural and structural design results, this stage is referred to as\textbf{ Robotic Process Design} or \textbf{Process Design }in short. In this thesis, I call these software functions as Computer-Aided-Manufacturing (\textbf{CAM}) functions, as the counterpart of the CAD functions for Assembly Design.

The process design software follows the model-centric programming approach described in the previous section, including the following steps. Steps (3) to (5) are repeated as many times as necessary while the engineer makes changes.
\begin{enumerate}
	\item \textbf{Creation of Process Model}
	\begin{itemize}
		\item The Process Model is created by combining the Assembly Model, Robot Model, Tool Models (Clamps, Docking Adapter and Grippers) and the Environment Model
		\item Subsequent computation updates this Process Model
	\end{itemize}

	\item \textbf{Task Planning}
	\begin{itemize}
		\item A sequential list of High Level Assembly Tasks is computed using a flowchart method \seeref{subsubsection:exploration-3-task-planning-with-flowchart}
		\item This list is expanded to a more comprehensive list of Low Level Tasks \seeref{subsubsection:exploration-3-expanding-task-groups}
	\end{itemize}

	\item \textbf{Compute Process Parameters / Accept User Changes}
	\begin{itemize}
		\item Process Parameters (such as Gripper and Clamp Choices) are computed based on the Assembly Model \seeref{subsubsection:exploration-3-process-parameters}
		\item Design rules are used to make decision automatically for parameters that have multiple options
		\item Parameters can be modified manually by the engineer if needed
	\end{itemize}

	\item \textbf{Compute Robot Targets and Object States}
	\begin{itemize}
		\item Robot Targets are computed automatically for each Robot Motion\\
        \seeref{subsubsection:exploration-3-compute-robot-targets}
		\item Object States are computed automatically for each Keyframe between Tasks \seeref{subsubsection:exploration-3-compute-object-states}
	\end{itemize}

	\item \textbf{Collision Detection and Keyframe Visualization}
	\begin{itemize}
		\item Scene states can be used for automatic collision detection
		\item Engineer can identify difficult manoeuvres visually based on intuition \seeref{subsubsection:exploration-3-process-visualization-and-adjustment}
	\end{itemize}

    \item \textbf{Multimodal Motion Planning (MMMP)}
	\begin{itemize}
		\item Robotic Motions are planned sequentially, ensuring continuity between robot configurations \seeref{subsection:exploration-3-multimodal-motion-planning-mmmp}
	\end{itemize}
\end{enumerate}

Figure \ref{fig:process-design-1} shows the Process Design Workflow, the highlighted (grey) portion represents the initial creation of the Process Model, which is essentially a wrapper around all other important models.

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.99\textwidth]{images/6a/process_1.pdf}
    \caption{Process Design Workflow - Creation of Process Model}
    \label{fig:process-design-1}
\end{figure}

\begin{itemize}
	\item \textbf{Assembly Model --} Obtained from Assembly Design Phase, contains beams, joints and assembly sequence \seeref{subsection:exploration-2-assembly-model-data-structure-and-functions}.

	\item \textbf{Robot Model --} A comprehensive model that describes the geometry and kinematics of the robot. The implementation used is based on compas\_fab, that is based on URDF and SRDF formats used in ROS moveit! Planning framework \parencite{SrdfROSWiki2023, UrdfROSWiki2023}.

	\item \textbf{Tool Models --} A model similar to the Robot Model. It is able to describe the geometry and kinematics of the tool. It also contains other parameters regarding how the tool can interact with timber beams and joints. The model is conceived to be prepared by the Tool Designer.

	\item \textbf{Construction Environment Model --} A geometrical model describing the static objects in the construction environment. The implementation in this thesis includes columns and floor of the laboratory, furniture and material stockpile. This model was constructed using a measuring probe from the iGPS system to measure the location of objects in the laboratory, and later modelling them using a rough representation. It shares the same frame of reference as the Robot Model. This approach has been used by other large scale projects in the past in the same laboratory \parencite{thomaRoboticFabricationBespoke2018}.

\end{itemize}

Throughout the subsections \ref{subsection:exploration-3-process-design-workflow}, the workflow diagram in Figure \ref{fig:process-design-1} will be repeated as a guide in the beginning of each sub-sections to indicate (grey box) which step is being discussed.

\FloatBarrier

\subsubsection{Task Planning with Flowchart}
\label{subsubsection:exploration-3-task-planning-with-flowchart}

Task planning refers to the creation of a list of tasks to accomplish a goal. The tasks relavent for the Clamping Process have been listed in \seeref{subsection:exploration-3-dirt-clamping-assembly-process-task-list-v2} using colloquial language.

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.99\textwidth]{images/6a/process_2.pdf}
    \caption{Process Design Workflow - Task Planning}
    \label{fig:process-design-2}
\end{figure}

\todo{The following paragraph is rephrased to make it more understandable. Meaning remains the same as before}In order to describe the task list in a way that can be processed by a computer automatically, the flowchart planning method was developed. The goal of which is to automate the creation of an assembly-task list by analyzing the properties of each timber element in the Assembly Model \parencite{huangNewAnalogProtocol2021}.

In the DiRT Clamping Assembly Process, different sets of assembly tasks are required depending on the number of joints a beam has with its neighbours. For example, the tools implemented in this round contains two gripper choices (PG1000 and PG1500) and two clamp choices (CL3 and CL3M). There are even more choices in later Exploration Rounds. When combined, there are many possible combinations of gripper and clamps for each beam. For example,

\begin{itemize}
	\item Beam assembled with Gripper, placing on the ground platform, fixed manually. No clamp used.

	\item Beam assembled with Gripper holding it and Clamp(s) clamping it to neighbouring beams at the shared joints.

	\begin{itemize}
		\item Gripper + One clamp

		\item Gripper + Two clamps

		\item Gripper + Three clamps

		\item Gripper + Four clamps (not used in the BusStop design)

	\end{itemize}
\end{itemize}
In order to be flexible for planning different scenarios and be generalizable for later development, the flowchart method uses \textbf{loops }and \textbf{conditionals }to plan the tasks. Figure \ref{fig:flowchart-for-planning-busstop} shows the flowchart used for planning the BusStop. It consists of a global loop (a) that iterates through each beam to be assembled, and two other loops (b) and (c) that iterates through the required clamps for the operations. A conditional (d) is used to decide whether the assembly requires synchronised clamping. Whenever the flowchart encounters a \textbf{Task}, that task is added to a \textbf{Task List}.

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.99\textwidth]{images/6a/flowchart-1.pdf}
    \caption{Flowchart for Planning the BusStop}
    \label{fig:flowchart-for-planning-busstop}
\end{figure}


Note that there are some variables used in the flowchart, they consist of \textbf{Assembly Model Parameters} and \textbf{Process Model Parameters}. At the beginning of this process design phase, the assembly motion parameters can be extracted from the Assembly Model but the process model parameters have not been computed yet. Therefore these parameters are left as a variable, the values of which can be binded later \seeref{subsubsection:exploration-3-expanding-task-groups}. This late binding technique is commonly used in TAMP context \parencite{garrettIntegratedTaskMotion2021, lozanoperezConstraintBasedMethodSolving2014}.
Table \ref{table:model-parameters-list} shows a list of Assembly and Process Model Parameters used in this round and how their values are computed (binded) dynamically.

\begin{table}[!h]
    \includegraphics[page=2, trim=25.4mm 190mm 25.4mm 25mm, clip, width=0.98\textwidth]{tables/Tables in Chapter 6.pdf}
    \caption{List of Assembly Model Parameters and Process Model Parameters}
    \label{table:model-parameters-list}
\end{table}

\FloatBarrier

\subsubsection{Expanding Task Groups}
\label{subsubsection:exploration-3-expanding-task-groups}

The list of tasks planned by the flowchart method is considered \textbf{High-Level Tasks }or \textbf{Task Groups}. Each of which can be expanded to a list of \textbf{Low-Level Tasks} that are directly related to the functions provided by the L2 and L3 controllers \seeref{subsection:exploration-2-distributed-control-system}. Table \ref{table:low-level-tasks-and-agents} lists all the low-level tasks used in this exploration round and the \textbf{Task Agents }(including the human operator) and Controller that are responsive for their execution.

\begin{table}[!h]
    \includegraphics[page=3, trim=25.4mm 160mm 25.4mm 33mm, clip, width=0.98\textwidth]{tables/Tables in Chapter 6.pdf}
    \caption{List of Low-Level Tasks and their Task Agents and Controllers}
    \label{table:low-level-tasks-and-agents}
\end{table}

Note the following properties:

\begin{itemize}
	\item Only \textbf{LM}, \textbf{FM }and \textbf{SM }require motion planning.

	\item Clamp and Robot Sync Linear Motion (SM) is provided by the L3 controller as it requires the coordination of the L2 Clamp Controller and the L2 ROS RRC Driver.

	\item Other L2 tasks are also executed through the L3 Process Controller because it provides flow control \seeref{subsection:exploration-2-process-execution-controller}.

\end{itemize}
Figure \ref{fig:task-group-1}, \ref{fig:task-group-2}, \ref{fig:task-group-3}, \ref{fig:task-group-4}, and \ref{fig:task-group-5} shows all the \textit{Task Groups} used in this exploration round expanded into its constituting low-level tasks (refer to Figure \ref{fig:legend-for-low-level-tasks} for a legend of the types of low-level tasks). The tasks that are marked with ``TC" are motion tasks that used a Taught Configuration for its target pose \seeref{subsection:exploration-3-taught-configuration-for-repetitive-targets}.

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.99\textwidth]{images/6a/motion-legend.pdf}
    \caption{Legend for Low Level Tasks}
    \label{fig:legend-for-low-level-tasks}
\end{figure}

\begin{figure}[!p]
    \centering
    \includegraphics[width=0.99\textwidth]{images/6a/lowleveltask-1.pdf}
    \caption{Task Group - Picking and Placing Clamps from Storage}
    \label{fig:task-group-1}
\end{figure}

\begin{figure}[!p]
    \centering
    \includegraphics[width=0.99\textwidth]{images/6a/lowleveltask-2.pdf}
    \caption{Task Group - Picking and Placing Grippers from Storage}
    \label{fig:task-group-2}
\end{figure}

\begin{figure}[!p]
    \centering
    \includegraphics[width=0.99\textwidth]{images/6a/lowleveltask-3.pdf}
    \caption{Task Group - Picking and Placing Clamps from Structure}
    \label{fig:task-group-3}
\end{figure}

\begin{figure}[!p]
    \centering
    \includegraphics[width=0.99\textwidth]{images/6a/lowleveltask-4.pdf}
    \caption{Task Group - Picking Beam from Storage and Placing on Ground Platform}
    \label{fig:task-group-4}
\end{figure}

\begin{figure}[!p]
    \centering
    \includegraphics[width=0.50\textwidth]{images/6a/lowleveltask-5.pdf}
    \caption{Task Group - Assembling Beam with Clamps}
    \label{fig:task-group-5}
\end{figure}

There are some useful techniques for designing the Low Level Tasks.

\begin{itemize}
	\item \textbf{Start with Free Motion --} Notice that all the High Level Tasks start with a Free Motion. This essentially means bringing the robot from wherever it was to this specific target at the beginning of this motion. This effectively allows the High Level Tasks to be decoupled from each other, allowing them to be modular and reusable within the flowchart.

	\item \textbf{Use Approach as First Target --} The target of the first free motion is often set at a small distance away from the actual target of interest. For example, in ‘PickClampFromStorage’, the robot is programmed to first arrive at an ‘approach’ point before moving linearly to insert the docking adapter into the tool-side. This gives the Free Motion Planner (FMP) more ‘room’ for planning the trajectory and results in shorter planning time.

	\item \textbf{Use Retract as Last Target --} Similar to the approach point, the retract point allows the robot to move freely away to the next task.

	\item \textbf{Use Linear Move for Narrow Passages --} The use of linear move can also help to explicitly define how the robot moves through a narrow gap. This is called the Narrow Passage problem in the field of motion planning. In the ‘PlaceClampToStructure’, the robot needs to slot the clamp around a timber beam where the hanging jaw is only slightly larger than the beam. The explicit use of two linear motions reduces the guesswork needed by the motion planner which results in shorter planning time.

	\item \textbf{Split Motions for changing Allowable Collision Matrix (ACM) --} Whenever the robot is making or breaking contact during the process, a different ACM is needed for planning purposes. For example in ‘AssembleBeamWithClamps’, the first free motion should not allow the active beam to collide with the clamps. However, in the subsequent linear move where the beam is placed into the clamp jaws, the ACM must allow this contact. Because each motion planning call can only support a fixed ACM, therefore an ACM change can be achieved by splitting the motion.

\end{itemize}

Figure \ref{fig:task-group-expanded} shows the planned \textbf{Task List} for assembling a beam that requires two clamps. Notice the total number of Low Level Tasks involved and the use of the high level tasks to make designing them easier.

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.99\textwidth]{images/6a/expand-to-low-level-task.pdf}
    \caption{Task Groups for assembling a beam, expanded to show the Low Level Tasks}
    \label{fig:task-group-expanded}
\end{figure}

\FloatBarrier

\subsubsection{Process Parameters}
\label{subsubsection:exploration-3-process-parameters}

After the task list is completed, the next step is to compute the process parameters. Process parameters are the parameters that are necessary to compute the details of the assembly process, such as Robotic Targets.

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.99\textwidth]{images/6a/process_3.pdf}
    \caption{Process Design Workflow - Process Parameters}
    \label{fig:process-design-3}
\end{figure}

Table \ref{table:process-parameters-list-and-sources} shows the most important process parameters used for the clamped assembly process, the first column lists the 1:1 relationship, and how the parameters are related to the models. For example, there is only one ``Assembly Sequence" in the whole Assembly Model, but there is one ``Designed Location" for every beam.

The second column lists the design phase where the values are generated. This can be Assembly Design (\textbf{AD}), Process Design (\textbf{PD}) and Tool Design (\textbf{TD}). In this PD phase, the production engineer’s role is to select suitable PD parameters such that the robotic process can be carried out.

The third column lists the domain expert involved in deciding the values. This can be Architectural and Structural Designer (\textbf{ASD}), Process Engineer (\textbf{PE}) and Tool Engineer (\textbf{TE}). It can also be Automatic Algorithms (\textbf{Auto}) that are used to infer the parameters from other parameters. In cases where the inference result has multiple possibilities, rule-based logic can be used for automatically making the selection. If necessary, the production engineer can also make adjustments to the selection.

\begin{table}[!hp]
    \includegraphics[page=4, trim=25.4mm 50mm 25.4mm 33mm, clip, width=0.98\textwidth]{tables/Tables in Chapter 6.pdf}
    \caption{List of Process Parameters and their sources}
    \label{table:process-parameters-list-and-sources}
\end{table}

The following three parameters regarding the parallel gripper is an example where parameter values were computed using rule-based logic. This is applied as the initial values before the production engineer reviews them:

\begin{itemize}
	\item \textbf{Gripper Choice --} The decision between the shorter PG500 and longer PG1000 can be made based on the length of the beam, the threshold was set at 1200mm.

	\item \textbf{Grasp Face --} The grasp face was selected such that the gripper faced downwards during assembly. For vertical columns, the gripper was chosen to face the centre of the structure.

	\item \textbf{Grasp Position --} The centre of the beam was used as default.

\end{itemize}
Based on the three parameters, the \textbf{Grasp Pose} (a transformation that relates between Gripper Grasp Frame and Beam Base Frame) is automatically computed. Note that there are numerous grasp pose possibilities. However, most of them are not viable because of collisions with the structure or the clamps. Nevertheless, this rule set was designed to maximise the chance of selecting a viable solution and helped reduce the work needed when the production engineer reviews them and makes changes to them.

Figure \ref{fig:ui-for-selecting-gripper-parameters} shows the interface for the production engineer to select the gripper parameters. Specifically, four different Grasp Face decisions are shown. Note that only one of them is viable because the others have collisions (highlighted in orange).


% 2 x 2 Images
\begin{figure}[!h]
    \centering
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/6a/img26.jpg}
        % \caption{SubFigureCaption}
        %\label{fig:uniquesubfigurelabel}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/6a/img27.jpg}
        % \caption{SubFigureCaption}
        %\label{fig:uniquesubfigurelabel}
    \end{subfigure}
    \vskip\baselineskip % Next row
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/6a/img28.jpg}
        % \caption{SubFigureCaption}
        %\label{fig:uniquesubfigurelabel}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/6a/img29.jpg}
        % \caption{SubFigureCaption}
        %\label{fig:uniquesubfigurelabel}
    \end{subfigure}
    \caption{User Interface for selecting Gripper Parameters, showing four different Grasp Face decisions}
    \label{fig:ui-for-selecting-gripper-parameters}
\end{figure}

Theoretically, a more advanced method would be to search the three parametric dimensions automatically to find a solution where the gripper does not cause collision. Additionally, it would be ideal to select a grasp position as close to the centre as possible to reduce imbalance. However, such algorithms were not implemented in the development because human intuition can often identify the solution fairly quickly.

\FloatBarrier

\subsubsection{Compute Robot Targets}
\label{subsubsection:exploration-3-compute-robot-targets}

\textbf{Robot target }refers to the goal pose of the robotic flange in each Robotic Motion (Linear and Free Motion) in the planned task list. It is also called the \textbf{Robot Flange Frame}, \textbf{Robot Frame}, or \textbf{Target Pose} depending on the context.

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.99\textwidth]{images/6a/process_4.pdf}
    \caption{Process Design Workflow - Compute Robot Targets}
    \label{fig:process-design-4}
\end{figure}

As seen earlier in the expanded low level task list, the assembly of one beam contains many robot motions and the whole assembly contains many more. Because of the non-repetitive geometry and position of the beams in the assembly design, the targets for each motion are mostly unique. Furthermore, the targets have to be recomputed for visualisation whenever the process parameters are changed. Therefore it is important to have an automated system to compute the targets to ensure an efficient Process Design workflow.

In case this is not obvious, all the concepts covered in the previous sections, such as the Assembly Model, Tool Models, Tasks, Task List, Process Parameters, are all designed in preparation for this computation step.

\paragraph{Kinematic Chain}

In order to understand how the robot targets are computated from the Assembly Model, is necessary to introduce the concept of the \textbf{Kinematic Chain} \parencite{lavallePlanningAlgorithms2006}. In the field of robot kinematics, the kinematic chain typically refers to the series of links and joints in the robot body \parencite{waldronKinematics2016}. However, in the context of motion planning it also includes the components that are attached to the body and the flange of the robot. In the DiRT clamping process, this includes the Docking Adapter, Clamps, Grippers and Beams. Because these components can be attached and detached during operation, the planning process have to be able to handle the change in the kinematic chain.
In order to allow a flexible combination of Tools and Beams, each of the kinematic link components are represented by their corresponding models, which are designed to allow are connected in a chain. Figure \ref{fig:kinematic-chain-of-the-robotic-system} shows the kinematic chain (after the robotic arm), when the robot is holding a beam in the gripper.

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.99\textwidth]{images/6a/robot-frame-propagation.pdf}
    \caption{Kinematic Chain of the Robotic System}
    \label{fig:kinematic-chain-of-the-robotic-system}
\end{figure}

The coloured boxes represent the computational models of the components in the chain and contain properties that describe them. They have \textbf{intrinsic properties}, values of which do not change during the process, and \textbf{extrinsic properties}, values of which can be changed by task agents. For example, the pose (a.k.a. Frame) of a Gripper is an extrinsic prosperity because it is changed when it is moved around.

The column on the left of the models shows the kinematic relationship between the pose of each object. Notice how they are related in a chain-like arrangement. Every component contains a base frame and a child frame. The geometrical relationship between the two is a \textbf{transformation function} \textbf{(T) }that can be extracted from the models. If this transformation function is defined as an intrinsic property of the component models, they can have a known and fixed value. Which means that as long as one of the frames in this frame is known, all the other frames in the chain can be computed, including the Robot Target at the top. On the right side of the diagram, is a flowchart that shows the application of the transformation to compute the up-chain or down-chain neighbours, once a single frame can be determined.

Note that the Grasp Pose is modelled as a component in the chain, even though it does not have a physical existence. This is because the grasp pose for each beam is variable from beam to beam, by treating it as a separate object that is created during Process Design, it avoids the complication of managing a changing transformation function in the Gripper Model.

\paragraph{Kinematic Switch}

The second important concept is that the kinematic chain can change during the assembly process whenever the robot is making or breaking contact with objects. For example, when picking up a beam or letting it go. The change in the kinematic chain is referred to as a \textbf{Kinematic Switch} \parencite{garrettIntegratedTaskMotion2021}.

Figure \ref{fig:kinematic-chain-arrangements} shows all the possible kinematic chain arrangements used during the DiRT clamping assembly process. These arrangements are called \textbf{modes }in MMMP. The bottom row of the diagram shows how the modes are switched between each other during the high-level tasks mentioned earlier \seeref{subsubsection:exploration-3-task-planning-with-flowchart}.

Note that some of the high level tasks can have more than one kinematic switch, and some can have none. It is just a coincidence that the tasks used in the clamp assembly process all had a one-to-one relationship with a kinematic switch.

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.99\textwidth]{images/6a/kinematic-chain.pdf}
    \caption{Different Kinematic Chains and Kinematic Switch in the DiRT Clamping Assembly Process}
    \label{fig:kinematic-chain-arrangements}
\end{figure}

In the DiRT clamp assembly process, the kinematic switches are indicated by a Tool Motion (a Low-Level Task). For example, switches between mode (a-b) and (a-c) are performed by the Docking Adapter using `Lock Tool` or `Unlock Tool`. Switches between mode (c-d) are performed by the Parallel Gripper using `Open Gripper` and `Close Gripper`.

\FloatBarrier

\paragraph{Computation Example One}

The following examples shows how the model of kinematic chains can be used to compute the robot targets for each motion. The following three examples are extracted from the flowchart for planning the BusStop demonstrator (Figure \ref{fig:flowchart-for-planning-busstop}).

Figure \ref{fig:exploration-three-low-level-tasks} shows the PickBeamFromStorage Task, as seen in Table \ref{table:low-level-tasks-and-agents}. The column on the left shows the sequence of low-level tasks (they are the same as before), which consist of one Free Motion, two Linear Motions and one Tool Motion. The kinematic chain during each motion is presented on the right hand including some of the important object frames (arranged horizontally for drawing convenience). Notice that the Tool Motion by the Gripper - Close Gripper created a kinematic switch.

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.99\textwidth]{images/6a/pick-beam-from-storage.pdf}
    \caption{Robotic target computation example 1 - PickBeamFromStorage}
    \label{fig:exploration-three-low-level-tasks}
\end{figure}

The computation begins by identifying Object Frames that are in a known position. In this case, the Gripper Location for Beam Pickup is fixed by design (such that the material loading location is the same every time for the operator). This parameter is fixed during Process Design, it is denoted by a \checkmark mark at step 3. The subsequent computation can proceed following the geometrical relationships between each step. The sequence of computation is indicated by the pointy arrows that originate from the \textit{known frame} with the \checkmark mark.

\begin{itemize}
	\item The Gripper Tool Motion in Step 3 created a kinematic switch but did not move any objects. Therefore the gripper frame for this step is equal to those in Step 2.

	\item The position of the gripper in Step 1 is the Approach Position towards the position in Step 2, the transformation (Gripper-Approach-Beam Direction) is defined in the Tool Model of the Gripper.

	\item The movement of the gripper in Step 4 after the pickup is defined during Process Design (it moves upwards in the world frame). Therefore its position can be computed from that in Step 3 by that transformation.

\end{itemize}
By definition, only Robotic Motions can change the position of components in the kinematic chain. Therefore the ‘equal’ relationship can be applied between frames whenever the task is not a Robotic Motion.

\FloatBarrier

\paragraph{Computation Example Two}

\todo{Added a few more sentence to explain the example}
Figure \ref{fig:chain-example-2} shows another example of computing robotic targets with the AssembleBeamWithClamps Task Group. The \textit{known frame} is the assembled location of the beam (retrieved from the Assembly Model) at Step 4. The sequence of computation goes from Step 4 towards Step 1 and Step 7. The kinematic chain is not shown at Step 5 for the Operator Inspection because the task has no effect on the kinematic chain or its components’ position. A kinematic switch happens at Step 6 when the gripper is opened, letting go of the beam.

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.99\textwidth]{images/6a/assemble-beam-with-clamps.pdf}
    \caption{Robotic target computation example 2 - AssembleBeamWithClamps}
    \label{fig:chain-example-2}
\end{figure}

\FloatBarrier

\paragraph{Computation Example Three}

\todo{Added a few more sentence to explain the example}
Figure \ref{fig:chain-example-3} shows a third example with the PlaceClampToStructure Task Group. The known frame is the pose of the clamp where it is hanging on the partially-assembled structure. Because there are two possible orientations where a clamp can be hanging on the structure, one of the two poses was selected by the Process Engineer during Process Design. The two transformations (Clamp-Attach-To-Beam Step 1 Direction) and (Clamp-Attach-To-Beam Step 1 Direction) are properties of the Clamp and are defined in its Tool Model. The sequence of computation goes from Step 3 towards Step 1 and Step 4 towards Step 7. A kinematic switch happens at Step 6 when the docking adapter is released, letting go of the clamp.

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.99\textwidth]{images/6a/motion-placeclamptostructure.pdf}
    \caption{Robotic target computation example 3 - PlaceClampToStorage}
    \label{fig:chain-example-3}
\end{figure}

\FloatBarrier

\subsubsection{Compute Object States}
\label{subsubsection:exploration-3-compute-object-states}

During the assembly process, the state of the RFL Robot, Clamps, Grippers and Beams are changed from step to step. While the previous step has computed the location of all the objects attached to the kinematic chain, it is still necessary to keep track of the states of the other objects that are not attached to the chain.

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.99\textwidth]{images/6a/process_5.pdf}
    \caption{Process Design Workflow - Compute Object States}
    \label{fig:process-design-5}
\end{figure}



The state of an object reflects what can be changed during the assembly process, therefore they belong to the extrinsic properties of the Models that represent them. The state includes more properties than just the pose of the object. For example, the Clamps and Grippers are kinematic and their collision geometry can change depending on their Joint Configuration (e.g. Gripper Finger position and Clamp Jaw position). Table \ref{table:object-states-list-and-sources} shows the state variables used for the Clamp Assembly Process.

\begin{table}[!h]
    \includegraphics[page=5, trim=25.4mm 190mm 25.4mm 33mm, clip, width=0.98\textwidth]{tables/Tables in Chapter 6.pdf}
    \caption{List of Object States and their sources}
    \label{table:object-states-list-and-sources}
\end{table}

Except for the Joint Configuration of the Robot, which is computed later by the MMMP solver, all the other states have to be computed in this step. The computation starts with a manually defined \textit{Initial State}, which is a full description including the joint configuration of the robot. In the Clamp Assembly Process, the initial state has the following properties:

\begin{itemize}
	\item Robot at parking position (gantry retracted up, arm folded in a compact way)
	\item All tools at their storage location
	\item Gripper fingers closed
	\item Clamp gripper closed, clamp jaw extended
	\item Beams positioned in a stack at beam storage location
\end{itemize}

Each of the low-level tasks is now seen as a function that causes a state change. In practice, this is implemented as a function in the Task Classes where a Starting State can be passed into the function and the Ending State is produced by updating the relevant parameters (see Figure \ref{fig:state-change-function}).

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.99\textwidth]{images/6a/updatestate.pdf}
    \caption{State change in relationship to the UpdateState() function}
    \label{fig:state-change-function}
\end{figure}


Table \ref{table:task-update-state-functions} below shows all the \codett{task.UpdateState()} function and what state parameters are being updated. For unaffected parameters, their states remain the same. Note that the Robot Motions (LM, FM and SM) require target parameters. These were computed in the previous step and are stored as parameters in the corresponding RobotMotion task objects. In addition, other targets such as TargetJawPosition for clamp jaw motion and TargetBeamFrame for operator to place beam were retrieved from the process parameters.

\begin{table}[!h]
    \includegraphics[page=6, trim=25.4mm 110mm 24.5mm 33mm, clip, width=0.98\textwidth]{tables/Tables in Chapter 6.pdf}
    \caption{List of Task.UpdateState() functions and the state parameters they update}
    \label{table:task-update-state-functions}
\end{table}


Because the task list is linear, the state update happens sequentially. The ending state of a task is used as the starting state input of the next task, this is continued until all the tasks are processed. I called the states in between \textbf{Intermediate States }and the last state as the \textbf{Final State, }or the \textbf{Goal State}. Figure \ref{fig:intermediate-states} shows the dual relationship between the task list and the states.

\begin{figure}[!hp]
    \centering
    \includegraphics[width=0.70\textwidth]{images/6a/tasklist.pdf}
    \caption{Diagram showing the initial state, the intermediate states and the final state of the process, and how they are related to the task list}
    \label{fig:intermediate-states}
\end{figure}


When one of these states is used to update the extrinsic parameters of the object models, this is referred to as a \textbf{Scene} \parencite{moveit!PlanningSceneROS2023}. With the exception of the robot configuration, a Scene is a complete description of all objects at a static moment. Figure \ref{fig:intrinsic-extrinsic-in-scene} shows a symbolic representation of the Scene.

\begin{figure}[!hp]
    \centering
    \includegraphics[width=0.70\textwidth]{images/6a/intrinsic-extrinsic.pdf}
    \caption{Diagram showing how the Object States affect the Extrinsic Properties in a Scene}
    \label{fig:intrinsic-extrinsic-in-scene}
\end{figure}

\FloatBarrier

\subsubsection{Process Visualization and Adjustment}
\label{subsubsection:exploration-3-process-visualization-and-adjustment}

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.99\textwidth]{images/6a/process_6.pdf}
    \caption{Process Design Workflow - Process Visualization and Adjustment}
    \label{fig:process-design-6}
\end{figure}

Up until this point, every parameter has been automatically computed from the initial Process Model and default values have been used for all the multiple-choice decisions. The process visualization step begins a cycle where the production engineer can visualize the assembly actions, identify problems, and make adjustments to the process parameters to correct them. Refer to the adjustable process parameters that are marked with Process Engineer (PE) \seeref{subsubsection:exploration-3-process-parameters}. Most of them are related to the gripper and the clamps.

\paragraph{Drawing Previews}

The screen capture image in Figure \ref{fig:rhino-interface-for-visualisation} shows how the process is visualised. A Rhino Command Interface was implemented to provide an interactive interface for the production engineer to step through the task list and visualise the scene at the end of each task. Extra controls are provided to jump to a specific beam or to skip through the non-robotic actions. The engineer is able to use all the 3D view control and rendering functions provided by the Rhino Viewport during this time.

Once a scene is selected, all the objects are drawn in the 3D modelling canvas based on the object models using their state parameters. The 3D models were initially implemented as mesh models because it is the default input format for motion planning. However, the implementation for visualisation was changed to using BRep Polysurfaces in Rhino because their solid boolean operations are easier to perform in Rhino.

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.99\textwidth]{images/6a/img41.jpg}
    \caption{Screen capture of the Rhino Interface showing a visualisation of the robotic assembly process}
    \label{fig:rhino-interface-for-visualisation}
\end{figure}

\paragraph{User Interaction}

The interface also allows the engineer to make changes to the process parameters. Figure \ref{fig:clamp_sync_linear_motion} shows the end of the \textit{Clamp and Robot Sync Linear Motion} for four different beams. The clamps are coloured green in the figure, the gripper in dark blue and the active beam in grey. Notice that the robot configuration is not yet resolved (MP is next step) and therefore the robot cannot be displayed. However, because the robot’s spherical wrist is in a known position regardless of IK configuration, it can be represented with a sphere to check for possible collision.

% 2 x 2 Images
\begin{figure}[!h]
    \centering
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/6a/img42.jpg}
        % \caption{SubFigureCaption}
        %\label{fig:uniquesubfigurelabel}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/6a/img43.jpg}
        % \caption{SubFigureCaption}
        %\label{fig:uniquesubfigurelabel}
    \end{subfigure}
    \vskip\baselineskip % Next row
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/6a/img44.jpg}
        % \caption{SubFigureCaption}
        %\label{fig:uniquesubfigurelabel}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/6a/img45.jpg}
        % \caption{SubFigureCaption}
        %\label{fig:uniquesubfigurelabel}
    \end{subfigure}
    \caption{User Interface showing the ending moment of the ClampSyncLinearMotion for four different beams}
    \label{fig:clamp_sync_linear_motion}
\end{figure}

\FloatBarrier

The screen capture images in Figure \ref{fig:visualisation-of-assembly-steps} show the \textit{visualisation of different assembly steps} for one beam.

\begin{itemize}
	\item Step 1 and 2 shows the clamps’ position before and after attaching the clamp to the Partially Assembled (PA) structure. It is a small movement that slides the clamp's hanging gripper into the timber structure.
	\item Step 3 and 4 shows the gripper’s and beam’s positions before and after being moved into the clamp jaws.
	\item Step 5 shows the position after the synchronised clamping.
	\item Step 6 shows the position after gripper release.
	\item Step 7 and 8 shows the clamp position before and after being detached.
\end{itemize}

Notice that in this specific case, the position of the gripper before approach (Step 3) and after retract (Step 6) are not the same, therefore both positions need to be checked. In the case of collision, the objects would change colour as an indication.

% 4 x 2 Images
\begin{figure}[!h]%
    \centering%
    \begin{subfigure}[b]{0.49\textwidth}%
        \centering
        \includegraphics[width=\textwidth]{images/6a/img46.jpg}%
        \caption*{Step 1}%
        %\label{fig:uniquesubfigurelabel}
    \end{subfigure}%
    \hfill
    \begin{subfigure}[b]{0.49\textwidth}%
        \centering
        \includegraphics[width=\textwidth]{images/6a/img47.jpg}%
        \caption*{Step 2}%
        %\label{fig:uniquesubfigurelabel}
    \end{subfigure}%
    \vskip\baselineskip % Next row
    \begin{subfigure}[b]{0.49\textwidth}%
        \centering
        \includegraphics[width=\textwidth]{images/6a/img48.jpg}%
        \caption*{Step 3}%
        %\label{fig:uniquesubfigurelabel}
    \end{subfigure}%
    \hfill
    \begin{subfigure}[b]{0.49\textwidth}%
        \centering
        \includegraphics[width=\textwidth]{images/6a/img49.jpg}%
        \caption*{Step 4}%
        %\label{fig:uniquesubfigurelabel}
    \end{subfigure}%
    \vskip\baselineskip % Next row
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/6a/img50.jpg}
        \caption*{Step 5}
        %\label{fig:uniquesubfigurelabel}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/6a/img51.jpg}
        \caption*{Step 6}
        %\label{fig:uniquesubfigurelabel}
    \end{subfigure}
    \vskip\baselineskip % Next row
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/6a/img52.jpg}
        \caption*{Step 7}
        %\label{fig:uniquesubfigurelabel}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/6a/img53.jpg}
        \caption*{Step 8}
        %\label{fig:uniquesubfigurelabel}
    \end{subfigure}

    \caption{Visualisation of eight selected assembly steps for one beam}
    \label{fig:visualisation-of-assembly-steps}
\end{figure}

\FloatBarrier

\todo{Sentence below rewritten to clarify what objects are in collisions}
It is important to understand that collisions can occur in some steps but not others.
For example, in Figure \ref{fig:collision-in-keyframes}, there are no collisions in the clamped keyframe (Figure \ref{fig:keyframe-no-collision}), but there are collisions in another keyframe (Figure \ref{fig:keyframe-no-collision}) between the gripper and the vertical timber beam.
Therefore, it is necessary for the production engineer to go through each beam and each step to ensure they are all collision free. Otherwise the subsequent motion planning process would fail to find a solution because objects were already in collision.

% 2 Horizontal Image
\begin{figure}[!h]
    \centering
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/6a/img54.jpg}
        \caption{No collision in this keyframe}
        \label{fig:keyframe-no-collision}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/6a/img55.jpg}
        \caption{Collision highlighted in orange}
        \label{fig:keyframe-has-collision}
    \end{subfigure}
    \caption{Visualization of two keyframes showing that collisions can occur in some keyframes but not others}
    \label{fig:collision-in-keyframes}
\end{figure}


In the next exploration round, an automatic collision check is implemented and the engineer only has to go through the steps that are in collision \seeref{subsection:exploration-4-fast-design-validation-with-ik-check}.

Aside from collisions, the engineer can also make adjustments to avoid potentially difficult situations, such as beam grasp that are too close to other neighbours or the ground, or highly eccentric grasp that are prone to deflection. The ground platform can also be adjusted if necessary and updates the environment model. Once the engineer is happy with the Process Model, it can be passed on for motion planning.

\FloatBarrier

\subsubsection{Multimodal Motion Planning (MMMP) Solver}
\label{subsubsection:exploration-3-multimodal-motion-planning-mmmp-solver}

The MMMP solver implemented for this exploration round is responsible for planning the robotic motions in the tasks list. It has access to the Linear Motion planner and Free Motion Planner for planning the two different types of motion accordingly. Non-robotic motions in the task list are ignored.

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.99\textwidth]{images/6a/process_7.pdf}
    \caption{Process Design Workflow - Multimodal Motion Planning (MMMP)}
    \label{fig:process-design-7}
\end{figure}

The major role of the solver is to ensure \textbf{trajectory continuity} between neighbouring motions in the task list. In the previous development round, this is ensured simply by planning the motions in a sequential way, such that the ending configuration of one motion can be used for the starting configuration of the next one. Figure \ref{fig:extract-ending-configuration} shows how the ending configuration (C1) of a motion (M1) can be extracted from its planned trajectory. C1 can then be used for planning the next motion (M2).

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.99\textwidth]{images/6a/image8.pdf}
    \caption{Diagram showing how the ending configuration of a motion can be extracted from its planned trajectory}
    \label{fig:extract-ending-configuration}
\end{figure}

\todo{The following 4 paragraphs are revised to have a clearer tone on what happened in the previous round vs this round.}
In the previous exploration round, if the motion planning failed, the planning routine was programmed to backtrack to the first motion of the failing beam (which is always a Free Motion) and restart the planning from there. The intention is that the highly stochastic Free Motion Planner (FMP) would result in a different ending configuration that is less likely to get stuck in the subsequent motion.

\todo{Paragrapgh rewritten to clarify what the problem of getting stuck. And why the Process Engineer is waiting 10h.}
This downside of this sequential planning method was discovered not long after it was used for this round. The algorithm often got stuck at one specific beam and cannot get past the beam. This is because all the motions are chained together in this round, instead of planning only a few motions per beam. In some cases, a full night (10h) of autonomous planning could only finish half of all the 40 beams because it got stuck. To make things worse, the planning difficulty only increased towards the end because the partial structure grew larger and presents a large obstacle for the FMP. It was a long cycle for the Process Engineer to make changes and wait to see if the planning can finish.

This problem was addressed by separating the task list into smaller \textbf{task groups} organised by each beam, this created 40 groups for the 40 beams that could be planned in parallel, or skipped when being stuck. When the task lists had to be stitched back together, the Free Movement in the beginning of each beam can be replanned using the two neighbouring configurations to ensure their continuity. In conclusion, the discovery of this problem led to a generalizable technique of using \textbf{Free Motion as a ‘glue’} that can connect separately planned segments together.

At a later stage of this Exploration Round, taught configuration was introduced for repetitive targets \seeref{subsection:exploration-3-taught-configuration-for-repetitive-targets}. This worsened the ‘stuck’ problem even within a Task Group. Another technique was subsequently developed to plan non-sequentially within a task group \seeref{subsection:exploration-3-non-sequential-planning-order}.

\subsubsection{Short Discussion about Process Design}
\label{subsubsection:exploration-3-short-discussion-about-process-design}

The development of the planning process in this section is a process of discovery that has its own significance.

Despite MP, TAMP and MMMP techniques have been demonstrated in many robotics research projects, applying them for timber construction, or architectural applications in general, require a significant adjustment to their parameters. Moreover, the integrated design and planning approach that is common in the architectural workflow has little precedence in the field of robotics where these algorithms were invented.

The development of High-Level Tasks, Low-Level Tasks, and the method of computing robot targets by geometrical relationship provided a unique solution for automatically parsing a design (i.e. the arrangement of beams and joints) into task and motion plans needed for autonomous execution. In addition, the discovery of process parameters that can have multiple options, formalised the workflow for how user input can be accommodated. It also opened the avenue for future work to automate these decisions using rule-based logic or searching techniques. This provided a roadmap for improving the process engineer’s role, from fixing collision problems, to designing the computational algorithms that can fix it automatically.

Finally this development has shown that, the planning flowchart, the high level tasks, the low level tasks, the geometrical relationships between robot targets and the ACM are specific to the construction method (DiRT clamping in this case) and will require project specific customization. While the tasks performed by these algorithms are similar to the work of a construction planner, the skillset to design them is rather specialised. It is still uncertain as to who will design them.

\subsection{Taught configuration for Repetitive Targets}
\label{subsection:exploration-3-taught-configuration-for-repetitive-targets}

\todo{Added first sentence to give a short intro of what is a taught configuration and point reader to the long intoduction of that.}
\textit{Teaching} is a technique for calibrating and saving a robot configuration for repetitive targets, the configuration that are saved is called a \textit{taught configuration} \seeref{subsection:introduction-inaccuracy-for-non-repetitive-targets}.
Taught configuration was added as an optional parameter in this round for all the Robot Motion Task. Whenever the taught configuration is defined, it is used as the starting configuration for motion planning instead of using Cartesian frame targets. Because the configuration is fixed, inverse kinematics (IK) is not required for planning the motion.

Taught configuration was used in the clamping process for repetitive targets, including the storage pose (for all the grippers and clamps) and the pickup pose for the gripper to pick up a beam. The enhance accuracy for reaching these locations is hypothesised to be ``worth the effort'' to implement additional planning logic for handeling taught configuration.

Figure \ref{fig:tool-storage-location} shows the tool storage location where taught configurations are used (one for each tool). A 3D-printed plastic pad was used to position the tools in a repeatable position on the aluminium platform. Figure \ref{fig:teaching-robot-configuration} shows a demonstration of \textbf{teaching} the robot configuration for picking up the tool. Similar process was used for the beam pickup configuration with the grippers.

% 2 Horizontal Image
\begin{figure}[!h]
    \centering
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/6a/img58.jpg}
        \caption{Locations where the tools are stored}
        \label{fig:tool-storage-location}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/6a/img59.jpg}
        \caption{Teaching the robot configuration for picking up the tool}
        \label{fig:teaching-robot-configuration}
    \end{subfigure}
    \caption{Photos showing how taught configuration are created for repetitive targets}
    \label{fig:taught-configurations}
\end{figure}

Taught configurations are typically acquired after the construction area is prepared and the storage stations are fixed. Considering a typical construction schedule (including this research project), it is unlikely that these configurations are available during the design and validation phase. In order to address this, an estimated configuration was used during the validation workflow \seeref{subsection:exploration-3-process-design-workflow}. The configurations were updated after the construction area was prepared, and the configurations were taught. The affected motions were then replanned.

\subsection{Non-Sequential Planning Order}
\label{subsection:exploration-3-non-sequential-planning-order}

\todo{This paragraph was originally belonging to the previous subsection, but it is more appropriate to be here.}
After the taught configurations were introduced, the planning method of sequentially planning chained motions no longer works. The success rate of planning a task group with taught configurations has dropped to zero - 0 success for each of the 40 beams, using 1800 seconds of maximum planning time.

\todo{This paragraph is rewritten to be more clear about the example.}
Upon further investigation, the cause was identified to be the interaction between the taught configuration and the Linear Motion Planner (LMP), but not the Free Motion Planner (FMP). Figure \ref{fig:taught-configurations-over-constraint} shows the a portion of the task group that is faced with the problem. In this example, M3 is a Linear Motion that contains a taught configuration. When sequential planning order is used, the Free Motion (M1) and Linear Motion (M2) would be planned first. The problem happends when the Linear Motion (M3) is planned, the ending configuration of M2 is carried forward to be the starting configuration for M3. On the other side, the taught configuration for the target of M3 is fixing its ending configuration. This means that the the LMP is constrained to use fixed configuration for both start and end points. This over-constrained the LMP, reducing the chance successful planning past this motion to be almost zero.

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.99\textwidth]{images/6a/image5.pdf}
    \caption{Diagram showing how taught configuration can cause over constraint problems with sequential planning}
    \label{fig:taught-configurations-over-constraint}
\end{figure}

\paragraph{Solution and Follow-Up}

The following solution was considered but was not successful:

\begin{itemize}
	\item \textbf{Remove this Linear Motion --} it is not possible because of the narrow passage problem \seeref{subsection:exploration-2-narrow-passage-problem}.
	\item \textbf{Plan Sequentially Backwards --} the over constraint scenario will still be encountered.

\end{itemize}

The solution that successfully addressed the problem consist of three parts:
\begin{itemize}
	\item A \textbf{priority flag }was added to the Motion Task to signify that it should be planned first.

	\item The process engineer can set this flag at the high-level task group template, and it would automatically appear in all motion tasks after Task Planning in the task list.

	\item The MMMP solver was modified to consider these flags and to plan the high priority task first. Figure \ref{fig:priority-flag} depicts how the MMMP solver would evaluate the priority flag and plan with a custom sequence.\footnote{The details of this discovery and the planning method have already been published. For implementation details, refer to \parencite{huangNewAnalogProtocol2021}.}

\end{itemize}

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.99\textwidth]{images/6a/image47.pdf}
    \caption{Diagram showing how the priority flag is used to plan the high priority task first}
    \label{fig:priority-flag}
\end{figure}

In summary, the departure from sequential planning order allowed the motions with more constraints (such as the Linear Motion next to a taught config) to be planned first. In this way, it was possible to avoid having both start and end config input for the LMP. The FMP, on the contrary, is able to handle the constraints and is planned the last. Figure \ref{fig:priority-flag-no-over-constraint} depicts the same \codett{PickToolFromStorage} Task.

Using the new method, Motion M3 and M4 would be flagged by the Process Engineer to be planned first, each of them will have one fixed config (directly from the taught config). Then M2 will be planned next (because LM has a higher priority than FM), it will also have one fixed config. M1 and M5 will be planned last, and will likely have two fixed configurations due to their neighbours before and after them. The FMG will have a much higher chance of bridging between the two constraints.

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.99\textwidth]{images/6a/planningorder-2.pdf}
    \caption{Diagram showing how the priority flag is used to plan the high priority task first}
    \label{fig:priority-flag-no-over-constraint}
\end{figure}


Figure \ref{fig:success-rate-and-runtime} \parencite{huangNewAnalogProtocol2021} shows the success rate and runtime for planning one task group (one beam) using the non-sequential (it is called nonlinear in the paper) versus sequential planning. Notice that the success rate for sequential planning is practically zero.

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.99\textwidth]{images/6a/img65.jpg}
    \caption{Chart showing the success rate and runtime for planning one task group (one beam) using the non-sequential versus sequential planning}
    \label{fig:success-rate-and-runtime}
\end{figure}


\FloatBarrier

\subsection{Standalone Process Execution Controller}
\label{subsection:exploration-3-standalone-process-execution-controller}

An improvement was made to upgrade the L3 Process Execution Controller that was based on Rhino Grasshopper \seeref{subsection:exploration-2-process-execution-controller}. The new controller is written in Python 3 code and utilises Tkinter to create an interactive graphical user interface (GUI). The user interface is shown in Figure \ref{fig:process-execution-controller}.

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.99\textwidth]{images/6a/img66.jpg}
    \caption{Screenshot of the Process Execution Controller}
    \label{fig:process-execution-controller}
\end{figure}


In addition to the previous capability of sending pre-planned motions to the L2 Robot Controller and L2 Clamp controller. It has the following new functionalities:

\begin{itemize}
	\item A table view of the sequential Task List organised by Beam and TaskGroup

	\item Provide a user interface for the operator to monitor the robot's state and execution progress

	\item Provides synchronised motions between L2 Clamp Controller and L2 Robot Controller to execute ‘Clamp and Robot Sync Linear Motion’

	\item Can send robot arm to the start or end state of action directly (Useful for retrying an action)

	\item Can monitor sensor readings and robot status

	\item Log execution events and surveyed results

\end{itemize}

The tasks that were supported by the Execution Controller are listed Table \ref{table:low-level-tasks-and-agents}. Each task has a corresponding execution function that specifies how it should be executed. They were developed according to the protocols provided by the controllers that provided the execution capability, in this case, compas\_rrc (L2) and the L2 Clamp Controller.

In theory each controller should provide a method to start a task, to query the state of the task, and to stop an ongoing task. However, the stopping function was not implemented in compas\_rrc until the next Exploration Round. This means that it was still not possible to stop an ongoing motion or to keep the two controllers in sync during an error stop \seeref{subsection:exploration-2-arm-and-clamps-out-of-sync-after-error}.

\paragraph{Operator Tasks}

There are two types of Operator Tasks in the process, OperatorLoadBeam and VisualInspection. When the execution controller encounters these tasks, a dialog will appear to show the operator the task instructions and the controller will wait for the operator to complete that task. The operator will need to click a button to confirm the task is finished before the next task is executed.

\paragraph{Execution Flow Control}

The controller maintains an execution pointer that points to a selected task in the list (visualized by a blue row among other tasks as shown in Figure \ref{fig:process-execution-controller}). The controller has four states:

\begin{itemize}
	\item \textbf{Stopped --} The initial state, no task is being executed.

	\item \textbf{Stepping --} This can be activated by the \textbf{Step Button}. The selected task will be executed immediately by the corresponding lower-level controllers. When the task is finished, the pointer will advance to point to the next task and the controller will go back to the Stopped state. This effectively executes only one task.

	\item \textbf{Running --} This can be activated by the \textbf{Run Button}. Similar to the stepping state, but after a task is finished, the controller will continue to execute the remaining tasks in the task list.

	\item \textbf{Error --} This state is entered automatically if the executing task has failed.

\end{itemize}
If the operator presses the \textbf{Stop Button}, the current task will be stopped immediately. The operator can also change from the Running state to the Step State at any time by using the \textbf{Step Button}. This effectively means the current task will be allowed to finish but the next one will not be started.

\paragraph{Implementation Challenges}

The main implementation challenge is to synchronise emergency stop signals between different Level 2 controllers. Stop signals can be raised by the ABB Controller (due to overload, collision, out of reach) and the clamp controller (due to clamp stalling or loss of signal). However, the Level 2 to Level 3 communication channel that was based on compas\_rrc implementation only supported a sequential, first-in-first-execute approach. This prevented any unplanned signals (such as the emergency stop) from being communicated out of sequence. Table \ref{table:sequential-communication-protocol-emergency-stop} shows the limitation of the sequential communication protocol when an emergency stop is encountered.

\begin{table}[!h]
    \includegraphics[page=7, trim=25.4mm 200mm 25.4mm 25mm, clip, width=0.98\textwidth]{tables/Tables in Chapter 6.pdf}
    \caption{Communication sequence in a sequential protocol when an emergency stop is encountered}
    \label{table:sequential-communication-protocol-emergency-stop}
\end{table}

An workaround was implemented to solve this problem, providing some improvement. The approach is to send only a small amount of targets in a short horizon and upon detection of a stop condition, discontinue the commands. However, this approach still causes a small amount of out-of-sync distance after the stop signal.

This problem was only truly resolved after this Exploration Round when developers of compas\_rrc upgraded the system to support real-time commands being passed on a second channel (Table \ref{table:two-channel-communication-protocol-emergency-stop}). The second channel allows the Level 3 controller to query the system status of the Level 2 controllers and can be performed frequently enough to detect emergency signals.

\begin{table}[!h]
    \includegraphics[page=8, trim=25.4mm 175mm 25.4mm 33mm, clip, width=0.98\textwidth]{tables/Tables in Chapter 6.pdf}
    \caption{Communication sequence in a two-channel protocol when an emergency stop is encountered}
    \label{table:two-channel-communication-protocol-emergency-stop}
\end{table}


\paragraph{Lesson learnt from this development}

A generalizable lesson learnt regarding the communication protocol between Level 2 (L2) to Level 3 (L3) controllers is that the use of a sequential commanding structure is incompatible with the time-critical synchronisation process that involves multiple controllers. This is relevant not only to DiRT operation but also systems such as 3D printing where a robotic arm is moving an extruder and the extruder mechanism is controlled by a separate controller.

\todo{Rewritten to explain the proposal more clearly. and to clarify that the proposal is a hypothetical system for future implementation.}
While the two-channel approach was successfully implemented in this round and used till the end of this thesis, I propose a hypothetical system for future exploration that uses only one channel while still providing the same functionality.
The proposed system utilize more states for describing a command, they are shown in Table \ref{table:single-channel-non-blocking-controller-states}. Only one communication channel is needed between L2 and L3 controllers. All the commands are initiated by the L3 controller, and they are always treated as a real-time non-blocking command by the L2 controller.

\begin{table}[!h]
    \includegraphics[page=9, trim=25.4mm 175mm 25.4mm 33mm, clip, width=0.98\textwidth]{tables/Tables in Chapter 6.pdf}
    \caption{Proposed L2 controller states for a single non-blocking channel}
    \label{table:single-channel-non-blocking-controller-states}
\end{table}


When the L2 controller receives a command, it makes the decision whether the command is queued, or to start running immediately depending on the current buffering level within the controller. Level 3 can make a further request to change the command status to \textbf{Pause }or to \textbf{Cancel }the command. Figure \ref{fig:state-changes-of-a-command} shows how the command state is changed. The labels (L2 or L3) indicate which controller is responsible of initiating the change.

For out-of-sequence commands, such as a status report request or a pause request, the Level 2 controller should directly execute the command upon reception and change its status to \textbf{Completed }immediately.

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.99\textwidth]{images/6a/command-buffer.pdf}
    \caption{Diagram showing changes of the command state in the proposed communication protocol}
    \label{fig:state-changes-of-a-command}
\end{figure}


Table \ref{table:single-channel-non-blocking-communication-protocol} illustrates the events during an emergency stop situation, how the Level 3 controller is informed, and how the error is cleared:

\begin{table}[!h]
    \includegraphics[page=10, trim=25.4mm 140mm 25.4mm 33mm, clip, width=0.98\textwidth]{tables/Tables in Chapter 6.pdf}
    \caption{Proposed communication protocol between L2 and L3 controllers with a single non-blocking channel}
    \label{table:single-channel-non-blocking-communication-protocol}
\end{table}

\FloatBarrier

\section{Demonstration}
\label{section:exploration-3-demonstration}

The demonstration structure is the same as the one used in the previous round. The timber beams were reused. The edges of lap joints that had less than 6mm chamfer were cut to 6mm, and those that were cut to 8mm still remained at 8mm \seeref{subsection:exploration-2-clamping-joints-with-chamfered-edges}.

\subsection{Execution Preparation}
\label{subsection:exploration-3-execution-plan}

The execution preparation was similar to the previous demonstration except that no test fit was necessary and many of the manually performed tasks were performed robotically. After the construction of the ground platform, the planned tasks were executed sequentially as planned. The new process is mostly automatic and only requires the operator to the load the beams to the robot gripper.

For the purpose of observation and debugging. A number of \textit{Operator Visual Inspection} tasks were also added to the planning template for introducing a pause to the other automatic process. They were considered only necessary during the development process and are not integral to the DiRT Assembly Process. The inspection happens at the following movements:

\begin{itemize}
	\item Checking if the alignment was good at critical moments before proceeding
    \begin{itemize}
        \item Before docking approach
        \item Before moving a clamp to the attachment location on a joint
    \end{itemize}

	\item Checking if a clamp was stable before unlocking and undocking them
	\item Checking if a placed beam is stable before releasing the gripper
	\item Checking if a beam is stable after picking it up from the storage location
\end{itemize}

\subsection{Construction Environment Setup}
\label{subsection:exploration-3-construction-environment-setup}

The location of the new ground platform \seeref{subsection:exploration-3-ground-platform-redesign} was located in a more central position under the robotic gantry in the robotic lab. This reduced the difficulty of the motion planning because there was more room on the sides for the robot to manipulate the long beams. Figure \ref{fig:controller-console} shows the controller’s console in relation to the ground platform.
Figure \ref{fig:environment-collision-model} shows the collision model used for the environment. The taught positions of the tools (red) can also be seen \seeref{subsection:exploration-3-taught-configuration-for-repetitive-targets}.

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.99\textwidth]{images/6b/img01.jpg}
    \caption{Photo of the controller’s console in relation to the ground platform}
    \label{fig:controller-console}
\end{figure}


\begin{figure}[!h]
    \centering
    \includegraphics[width=0.99\textwidth]{images/6b/img02.jpg}
    \caption{Environment Collision Model used for motion planning}
    \label{fig:environment-collision-model}
\end{figure}

Figure \ref{fig:tools-and-timber-beams} shows the four clamps (CL3 and CL3M) and the short gripper (PG500) placed in their storage location. The reused timber beams of the BusStop Pavilion can be seen in the background, sorted, and ready for assembly. The holes used to adjust column height in the last test can be seen at some column ends. These holes were not used in this round because the columns will sit flush with the aluminium platform.

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.99\textwidth]{images/6b/img03.jpg}
    \caption{Photo showing the tools and the timber beams ready for assembly}
    \label{fig:tools-and-timber-beams}
\end{figure}


\subsection{Scaffolding and Screw Test}
\label{subsection:exploration-3-scaffolding-and-screw-test}

After the previous round, it was clear that the new robotic operations would not be possible if the Partially Assembled (PA) structure had a large deformation. Figure \ref{fig:scaffolding-bars} show the aluminium bars added during construction by manually clamping them to the structure. They simulate a scenario where the stationary-side structure is properly supported and does not deform substantially. This allowed the study of the robot-side inaccuracy separate from the stationary-side. In addition, wood screws were added to the lap joint to prevent loose joints from opening up after they were assembled \seeref{subsection:exploration-2-joints-loosening-after-assembly}.

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.99\textwidth]{images/6b/img04.png}
    \caption{Photo showing scaffolding bars added to the structure to prevent deformation}
    \label{fig:scaffolding-bars}
\end{figure}

\FloatBarrier

\section{Lessons Learnt}
\label{section:exploration-3-lessons-learnt}

\subsection{Successful Validation}
\label{subsection:exploration-3-successful-validation}

\subsubsection{Automatic Clamp Placement}
\label{subsubsection:exploration-3-automatic-clamp-placement}

The automatic placement and retrieval of clamps was found to be possible, thereby validating one of the core principles of the Distributed Robotic Tools (DiRT) system.

However, the process is not capable of full autonomy because of alignment problems and the lack of sensors that can detect the misalignment \seerefii{subsection:exploration-3-beam-placement-misalignment}{subsection:exploration-3-docking-adapter-misalignment}. This required the operator to constantly monitor the system by physically walking into the construction area. Not only that it is dangerous but also not very effective because many of the alignment locations are far from the ground.

Figure \ref{fig:robot-picking-up-clamp} shows the robot having picked-up a clamp from the structure. A jerry rigged camera (pink) can be seen installed on the flange to help with docking alignment \seeref{subsection:exploration-3-docking-adapter-alignment-with-camera}.

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.99\textwidth]{images/6b/img05.png}
    \caption{Photo showing the robot having picked-up a clamp from the structure}
    \label{fig:robot-picking-up-clamp}
\end{figure}


\subsubsection{Stability by Scaffolding}
\label{subsubsection:exploration-3-stability-by-scaffolding}

The manual addition of scaffolding to support the columns was found to be helpful in stiffening the structure, indicating that this could be a viable strategy for future construction process. Figure \ref{fig:scaffolding-bars-2} shows the scaffolding bars added to stabilise the structure. The location of the bars were determined on-the-spot by the operator by observing how the structure would lean or deform. This intuitive estimation was found to be possible. However, the associated problem with these added elements is that the robot can collide with it \seeref{subsection:exploration-3-robot-collision-with-scaffolding}.

The discovery of the effectiveness of the scaffolding bars led to the development of a more systematic method of adding temporary scaffolding in Exploration Round 5 \seerefii{section:exploration-5-goal}{subsection:exploration-5-scaffolding-support-during-assembly}.

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.99\textwidth]{images/6b/img06.jpg}
    \caption{Photo showing the scaffolding bars added to stabilise the structure}
    \label{fig:scaffolding-bars-2}
\end{figure}

\subsubsection{Screws Preventing Joints Opening Up}
\label{subsubsection:exploration-3-screws-preventing-joints-opening-up}

A small wood screw (5 x 80mm) was added manually to some of the lap joints to prevent them from opening up.

After the clamping operation of a beam and during the release of the clamp, the tightness of the lap joint was assessed by the operator. A manual push was used to determine if the joints needed to be fixed. If so, a battery-powered screwdriver was used to insert a screw into the lap joint, penetrating the two beams. No pre-drilled holes were used because of the small screw size.

Despite the small size of the screw, it was found to be sufficient in holding the joint in place, preventing them from opening up. They also appeared to have helped stiffen the structure. However, this effect was not conclusive.

Theoretically, this screw is not bearing the structural load of the structure, but only to prevent joints from accidentally opening up. This discovery provided useful information for later development of a screwdriver for closing joints in the next Exploration Round \seeref{section:exploration-4-goal}.

\subsubsection{Debugging with the Process Execution Controller}
\label{subsubsection:exploration-3-debugging-with-the-process-execution-controller}

The process execution controller \seeref{subsection:exploration-3-standalone-process-execution-controller} was found to be very helpful during the execution of the planned tasks.

\begin{itemize}
	\item \textbf{Rewind and try again --} Using the task list in the table view, it is easy to select an earlier state to rewind the robot and tools back to an earlier state for debugging purposes.

	\item \textbf{Reprogramme the execution behaviour --} Because the \textit{execute() }function for each type of task is only binded when the L3 controller loads the planned tasks and motion. The execution behaviour can be changed easily during the debugging phase by modifying the execution code and reloading the planned motions. For example, the \textit{Lock Tool }task by the docking adapter was modified this way to include checking new sensors (\seeref{subsection:exploration-4-docking-adapter-lock-sensor}.

	\item \textbf{Table view provided a good overview --} The table view of tasks provided a good overview of what is about to be executed, This increased the confidence of the operator to not worry about incorrect programming causing dangerous execution.

	\item \textbf{Logging --} The data that can be logged with this system was found to be very helpful in debugging. The almost-real-time commands and replies from various controllers would otherwise be impossible to read from a console.

\end{itemize}
\subsection{Beam Placement Misalignment}
\label{subsection:exploration-3-beam-placement-misalignment}

Despite the inclusion of temporary scaffolding during construction, which reduced the deformation of the PA structure, the beam alignment at its target position is still very poor.

\begin{itemize}
	\item For beams that were aligned to the PA structure -- joint to joint alignments, the misalignment is too bad to be clamped successfully. \todo{Tenses in this list have been revised to be consistently past tense.}

    \begin{itemize}
        \item On many occasions, I manually jogged the robot to align the joints visually. The deviation often requires 10 to 20mm of offset on the linear gantry and 2 to 4 degrees on the last joint of the robotic arm to be corrected. No pattern was observed between the offset amount.

        \item I perform manual jogging too often that I added an `OperatorAddVisualOffset` Movement in the list of tasks and created a function for applying the offset to subsequent assembly and gripper retract movement.

    \end{itemize}

	\item For beams that were placed on the ground platform, the final target is somewhat consistently lower than the point where the beam touches the platform.
    \begin{itemize}
        \item This usually pushed the beam to slip within the gripper fingers, sometimes causing an overload error on the robot controller.

        \item Occationally, the beam deviates in the horizontal plane where it touches the platform. This was conveniently measurable with a tape measure because the vertical elements are arranged in a grid.
    \end{itemize}
\end{itemize}

\paragraph{Intermediate Solution}

Because of poor alignment, a temporary solution was added to allow the operator to offset the joint values such that the assembly process can continue. The operator was able to make adjustment for all nine axis and make small movements using an trial and error approach. Figure \ref{fig:offsets-applied-manually} shows the offsets that was applied to the robot for successfully aligning and docking with the tool changer when retrieving a clamp from the structure.

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.99\textwidth]{images/6b/img07.png}
    \caption{Graph showing the offsets applied to the robot for successfully placing the beam}
    \label{fig:offsets-applied-manually}
\end{figure}


{\footnotesize Number of measured data points $= 29$ \\ Mean Value (after discarding top and bottom 5\% outlier) $= 9.1mm$}

Although the data shows the distribution of the deviation, it is not possible to draw conclusion whether the inaccuracy comes from the robot-side or the stationary-side. It is most likely a combination of the two because the clamps also visibly move during the clamping movement.

\FloatBarrier

\paragraph{Possible Cause}

Another investigation was conducted for the placement of beams when the misalignment was bad. Two different types of observations were made, to compare real world position and the position in the CAD model. In both cases, gripper-to-beam positions were first checked to ensure it is grasped correctly.

\begin{itemize}
	\item \textbf{Alignment to the ground platform --} Since the platform is measured with iGPS, its position in the CAD environment is highly accurate. The beam was sent to a known target above the platform, and its deviation is measured against it. In some cases, the error in the vertical direction is more than 10mm from the model in the CAD software.

	\item \textbf{Alignment to other joints on the PA structure --} Since the PA structure sits accurately on the ground platform, and is supported by scaffolding, the location of the joints are reasonably accurate. However, misalignments between mating joints can also exceed 10mm.

\end{itemize}

Because of these two observations, I concluded that the source of error on the robot-side is so significant that no matter how stable the PA structure is, it is still beyond what the chamfered edges can correct.

The following list explored the possible source of error on the robot-side in the kinematic chain, starting from the gantry, ending at the timber.

\begin{itemize}
	\item \textbf{Robotic platform}

\begin{itemize}
	\item Inaccuracy due to the mechanical system

	\item Inaccuracy due to the IK / FK conversion

\end{itemize}
	\item \textbf{Docking adapter}

\begin{itemize}
	\item The docking adapter is a commercially available and reliable component, the docking accuracy is published by Schunk to be 0.015mm. Although no data is available for orientation error, it is not likely to be the major factor.

\end{itemize}
    \item\textbf{PG Gripper}

\begin{itemize}
	\item The gripper is inspected for CAD-to-reality error. The build was found to be fairly accurate, likely within 0.5mm deviation. This source of error cannot be the major factor.

\end{itemize}
    \item\textbf{Slip between PG Gripper and Beam during beam transfer}

\begin{itemize}
	\item This is ruled out because the grasp pose is confirmed to be accurate before the measurement.

\end{itemize}
    \item\textbf{Beam and Joint Geometry}

\begin{itemize}
	\item This is ruled out after measurement. The deviations of the beam between joint positions are all within 1mm. Furthermore, the structure is known to fit together.

\end{itemize}
\end{itemize}

\paragraph{Possible Solution and Follow-Up}

The only possible explanation of the large deviation (in the range of >10mm) is the error from the robotic platform. This led to a separate investigation in the next Exploration Round to determine the severity of the robot’s inaccuracy \seeref{subsection:exploration-3-rfl-robot-inaccuracy-and-calibration}.

\subsection{Docking Adapter Misalignment}
\label{subsection:exploration-3-docking-adapter-misalignment}

Similar to the problem mentioned in the previous section. The misalignment between the robot-side and the tool-side of the docking adapter can also be severe enough that the conical part of the robot-side adapter cannot be inserted into the tool-side. This happened in two scenarios:

\begin{itemize}
	\item When trying to pick up used clamps from the PA structure (PickClampFromStructure). There is a less than 10\% success rate.

	\item When picking up a clamp from storage (PickClampFromStorage), the alignment is very good and is 100\% successful. The difference between the two cases is that the storage position is a taught configuration.

\end{itemize}
In these cases, either I manually jogged the robot to alignment, or pushed the PA Structure such that the adapter aligns. For the jogged cases, the approach is similar to the previous section, Figure \ref{fig:offsets-applied-manually-2} shows the offset distance:

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.99\textwidth]{images/6b/img08.png}
    \caption{Graph showing the offsets applied to the robot for successfully aligning the Docking Adapter}
    \label{fig:offsets-applied-manually-2}
\end{figure}

{\footnotesize Number of measured data points $=$ 54 \\ Mean Value (after discarding top and bottom 5\% outlier) $=$ 10.7mm}

\paragraph{Possible Cause}

The cause is similar to another problem \seeref{subsection:exploration-3-beam-placement-misalignment}. However, the fact that the clamp is hanging from the PA structure is likely to have more error. Unfortunately this was difficult to quantify.

Note that the maximum permissible XY axis offset for the Schunk Tool Changer to successfully lock is 2mm, which is significantly smaller tolerance than the timber joints. This may explain the very low success rate.

In the case of PickClampFromStorage, the use of taught configuration, resulting in 100\% success rate confirms that the robot is very repeatable.

\paragraph{Possible Solution and Follow-Up}

\begin{itemize}
	\item \textbf{Taught configuration} is confirmed to be very accurate. They are used for all repeatable positions in future demonstrations, such as tool storage positions and material pickup positions.

	\item \textbf{Redesign the docking adapter} to accept more deviation.

\begin{itemize}
	\item Not pursued because of budget limitations.

\end{itemize}
	\item \textbf{Active Correction by camera marker guidance --} A camera mounted on the robot-side, looking at a fiducial marker mounted on the tool-side to guide the robot into alignment.

\begin{itemize}
	\item Developed and tested successfully in Exploration Round 4 \seerefii{subsection:exploration-4-camera-marker-alignment-correction-system}{subsection:exploration-4-camera-marker-hardware-on-docking-adapter}.

\end{itemize}
	\item  \textbf{Active Correction by docking probe} - A two-axis joystick like probe can be used to guide the robot into alignment.

\begin{itemize}
	\item Not pursued in favour of the non-contact alignment method. The camera method can directly acquire the deviation in 6DOF, which is more capable than a mechanical solution.

\end{itemize}
\end{itemize}

\subsection{Docking Adapter Fail to Lock}
\label{subsection:exploration-3-docking-adapter-fail-to-lock}

In some occasions, after the docking adapter is inserted within each other, and the pneumatic lock on the robot-side is activated, the docking adapter would fail to lock. This sets off a series of cascading events that, if not stopped, could result in damage:

\begin{enumerate}
	\item The failure to lock could not be detected automatically because the lock sensor (which was already installed to the robot-side) was not connected.

	\item The execution controller was not programmed to acquire a confirmation signal but simply assume the lock was successful after 4s. Therefore the execution pointer is moved to the next movement.

	\item The next movement is to release the clamp, this is performed by actuating the pneumatic clamp gripper through the feed-through on the docking adapter.

	\item Because the lock was not successful, the feed-through would leak causing a loud noise. Typically this would alert me to stop the system and fix the problem.

	\item If the system is not stopped in time, the execution controller would continue to move the execution pointer to the next move because the gripper actuator also lacks a sensor to detect its failure.

	\item The next two movements are the robotic arm detaching the clamp with linear movements. Since the clamp is not properly locked to the robotic arm and that the gripper is not released, the robotic arm moving away from the clamp can cause it to bend around the attachment location and result in a fall.

\end{enumerate}

Fortunately, this problem has always been detected and stopped at step 4. I can then fix the problem by:

\begin{itemize}
	\item \textbf{Rewinding the execution state }to before the activation of the lock, give the clamp a push while attempting to activate the lock again. In most of the cases, the shaking solves the problem.

	\item \textbf{Manually jog the robot} in small linear or orientation increments before trying the lock again. It is relatively time consuming when manual jog is needed.

\end{itemize}
\paragraph{Possible Cause}

\begin{itemize}
	\item \textbf{Robotic arm or the clamp attachment being too stiff --} Even though the docking adapter is inserted, the locking action requires at least one of the two sides to be flexible enough to be pulled together. Even though the misalignment may be small, the stiffness on both sides prevents the lock from closing the gap.

\begin{itemize}
	\item Note that automatic tool changers, like this Schunk SWA 040, are designed for tool change at a storage location. The tool-side is often not held down by a stiff attachment.

\end{itemize}
	\item \textbf{Alignment deviation too large --} Even though the adapter is inserted into each other, the deviation can still be larger than the allowable tolerance.

\begin{itemize}
	\item Docking adapter is not oriented accurately.

	\item Docking adapter is not inserted deep enough.

\end{itemize}
\end{itemize}
\paragraph{Possible Solution and Follow-Up}

\begin{itemize}
	\item \textbf{Redesign the docking adapter} to acquire lock even under deviation. And the docking accuracy is regained after one of the sides is no longer stiff.

\begin{itemize}
	\item Not pursued because of budget limitations.

\end{itemize}
	\item \textbf{Enable compliance control on robotic arm --} reduce stiffness of the robotic arm side after insertion is successful.

\begin{itemize}
	\item Tested with success but only in combination with the camera correction method \seeref{subsubsection:exploration-4-robot-compliant-control-and-passive-alignment}.

\end{itemize}
	\item \textbf{Active Correction by camera marker guidance --} Same as mentioned before \seeref{subsection:exploration-3-docking-adapter-misalignment}.

\begin{itemize}
	\item Developed and tested successfully in Exploration Round 4\\
    \seeref{subsection:exploration-4-camera-marker-alignment-correction-system}

\end{itemize}
	\item \textbf{Shake the robot-side automatically --} The robot can be programmed to perform a small shaking movement similar to the one performed by hand.

\begin{itemize}
	\item Developed and tested successfully in Exploration Round 5 \seeref{subsection:exploration-5-automatic-shake-when-docking-with-tools}

\end{itemize}
\end{itemize}

\subsection{Docking Adapter Alignment with Camera}
\label{subsection:exploration-3-docking-adapter-alignment-with-camera}

In an attempt to understand if the docking adapter alignment can be solved by a camera solution, I attached a small WiFi camera (based on Raspberry Pi CAM) on the tool-side of the docking adapter, and attached a small calibration target pattern printed on paper and glued to a mounting bracket.

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.99\textwidth]{images/6b/img09.jpg}
    \caption{Photo showing the alignment camera mounted on the tool-side of the docking adapter}
    %\label{fig:uniquefigurelabel}
\end{figure}


% 2 Horizontal Image
\begin{figure}[!h]
    \centering
    \begin{minipage}{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/6b/img11.jpg}
        \caption{Photo showing an Alignment Target as seen by the Docking Camera}
        \label{fig:alignment-target-as-seen}
    \end{minipage}
    \hfill
    \begin{minipage}{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/6b/img10.jpg}
        \caption{Photo showing the Alignment Targets installed on all the clamps}
        \label{fig:alignment-targets-on-clamps}
    \end{minipage}
    % \caption{FigureCaption}
    %\label{fig:uniquefigurelabel}
\end{figure}


An alignment routine was added to the Process Execution Controller to involve the operator for aligning the docking adapter. A video feed with digitally overlaid blue and red marks was shown to the operator (see Figure \ref{fig:alignment-target-as-seen}) and the operator can type in misalignments values. The XY misalignment can be read from the red mark position over the target and the Z misalignment (distance to target) can be guessed using the relative size of the blue marks over the target. The robot is then instructed to move to the offsetted position and the observation is repeated until all marks are aligned as best as possible. However, due to the activation of only three Cartesian axes, the correction can only compensate for position but not orientation error.

\paragraph{Observation}

This alignment method was tested 59 times during the robotic construction process.  It often takes a few attempts for the operator to align all the marks. The resulting success rate for the tool changer to insert the conical part into the tool-side is above 90\%. However, even though the insertion can be successful, the problem of failing to lock was still present. Figure \ref{fig:remote-camera-offset} shows the offset that was applied to successfully dock with the docking adapter.

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.99\textwidth]{images/6b/img12.png}
    \caption{Graph showing the offsets applied to the robot for successfully aligning the Docking Adapter - Using Remote Camera}
    \label{fig:remote-camera-offset}
\end{figure}


{\footnotesize Number of measured data points $=$ 59 \\ Mean deviation value (after discarding top and bottom 5\% outlier) $=$ 10.04mm\par}

\paragraph{Possible Solution and Follow-Up}

This experiment indicated that the visual docking method is a promising approach. Leading to the development of a fully automatic camera marker correction mechanism in the next Exploration Round \seeref{subsection:exploration-4-camera-marker-alignment-correction-system}.

After this positional correction and successful insertion, the docking adapter is still suffering from failure to lock. This indicated that the locking problem is likely the result of orientation error and overly stiff docking pair \seeref{subsection:exploration-3-docking-adapter-fail-to-lock}.

\subsection{Robot Collision with Scaffolding}
\label{subsection:exploration-3-robot-collision-with-scaffolding}

Due to the unplanned use of scaffolding to support the unstable structure. The pre-planned robotic motion caused collision of the moving objects with the scaffolding bar and clamps. Figure \ref{fig:robot-colliding-with-scaffolding-bar} show an imminent collision between the timber beam held by the robot and a scaffolding bar.

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.99\textwidth]{images/6b/img13.jpg}
    \caption{Photo showing a timber beam held by the RFL robot colliding with a scaffolding bar}
    \label{fig:robot-colliding-with-scaffolding-bar}
\end{figure}


% 2 Horizontal Image
\begin{figure}[!h]
    \centering
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/6b/img14.jpg}
        \caption{Temporary Scaffolding Clamps}
        %\label{fig:uniquesubfigurelabel}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/6b/img15.jpg}
        \caption{Imminent Collision}
        %\label{fig:uniquesubfigurelabel}
    \end{subfigure}
    \caption{Photos showing imminent collision from a different angle}
    %\label{fig:uniquefigurelabel}
\end{figure}


Collisions also happened with the documentation camera on a tripod. However, that camera is unrelated to the construction process.

\paragraph{Possible Solution and Follow-Up}

\begin{itemize}
	\item \textbf{Include scaffolding in motion planning --} in Exploration Round 5, the use of scaffolding is a planned act. The location and geometry of the scaffolding bars can therefore be included as collision geometry during motion planning. \seeref{subsection:exploration-5-scaffolding-support-during-assembly}.

	\item \textbf{Sensing collision geometry around robot --} If a dynamic point cloud scanner were to be used for scanning the area surrounding the robot during operation, the robot can potentially navigate around the newfound obstacle and would not be limited to the planned collision geometry.

\begin{itemize}
	\item Existing research literature in autonomous robotics have developed many different techniques for sensing and replanning. \parencite{elbanhawiSamplingBasedRobotMotion2014} However, due to the lack of expertise in these fields, the development was not pursued.

\end{itemize}
	\item \textbf{Do not use scaffolding --} in Exploration Round 4, deformation-aware design principles and error correction method was developed \seeref{subsection:exploration-4-deformation-awareness-and-error-correction-by-triangulation}. The demonstrator can be designed to be stable and with limited deformation for all the incomplete states in the entire assembly process. This eliminated the need for any scaffolding during assembly.

\end{itemize}

\subsection{Redundant Clamp Detach Attach Actions}
\label{subsection:exploration-3-redundant-clamp-detach-attach-actions}

The task planning method using a flowchart was found to produce a number of redundant tasks regarding tool changes. This is because of the cyclic nature of the flowchart that considered only the tasks necessary for one beam.

\paragraph{Possible Cause}

In order to illustrate the problem, consider the task list below for two beams (b1 and b2). Each of them was clamped using the same clamps (c1, c2). They would have an almost identical task list such as the following:

\begin{enumerate}[nosep]

	\item {\footnotesize Tasks for Beam (b1) }
    \begin{enumerate}
        \item {\footnotesize PickClampFromStorage (c1)}
        \item {\footnotesize PlaceClampToStructure (c1)}
        \item {\footnotesize PickClampFromStorage (c2)}
        \item {\footnotesize PlaceClampToStructure (c2)}
        \item {\footnotesize PickGripperFromStorage (g1)}
        \item {\footnotesize PickBeamFromStorage (b1)}
        \item {\footnotesize PlaceBeamInClamp (b1, g1, [c1])}
        \item {\footnotesize AssembleBeamWithClamps (b1, g1, [c1])}
        \item {\footnotesize PlaceGripperToStorage (g1)}
        \item {\footnotesize PickClampFromStructure (c2)}
        \item {\footnotesize PlaceClampToStorage (c2)}
        \item {\footnotesize PickClampFromStructure (c1)}
        \item {\footnotesize PlaceClampToStorage (c1)}
    \end{enumerate}

	\item {\footnotesize Tasks for Beam (b2) }
    \begin{enumerate}
        \item {\footnotesize PickClampFromStorage (c1)}
        \item {\footnotesize PlaceClampToStructure (c1)}
        \item {\footnotesize PickClampFromStorage (c2)}
        \item {\footnotesize PlaceClampToStructure (c2)}
        \item {\footnotesize PickGripperFromStorage (g1)}
        \item {\footnotesize PickBeamFromStorage (b2)}
        \item {\footnotesize PlaceBeamInClamp (b2, g1, [c1])}
        \item {\footnotesize AssembleBeamWithClamps (b2, g1, [c1])}
        \item {\footnotesize PlaceGripperToStorage (g1)}
        \item {\footnotesize PickClampFromStructure (c2)}
        \item {\footnotesize PlaceClampToStorage (c2)}
        \item {\footnotesize PickClampFromStructure (c1)}
        \item {\footnotesize PlaceClampToStorage (c1)}
    \end{enumerate}

\end{enumerate}

Notice that at the end of the first beam and the beginning of the next one, the robot will PickClampFromStructure (c1), PlaceClampToStorage (c1), PickClampFromStorage (c1), and finally PlaceClampToStructure (c1). The PlaceClampToStorage (c1) and PickClampFromStorage (c1) are redundant. Cancelling out these two actions would allow the clamp to go directly from one area of the structure to another area directly.

Conceptually, this is a simple elimination step. However, because the flow chart method is iterating based on one cycle per beam, it is difficult to reason about when to retrieve the clamps or not based on the situation in the previous or next beams. Furthermore, if a clamp is left on the structure, to be retrieved at a later time, there is no guarantee that the clamp can still be accessible. For example, the access could have been blocked by the addition of elements.

\paragraph{Possible Solution and Follow-Up}

This problem is a classical reason for using automatic task planning that is developed by the robotics community \parencite{ghallabAutomatedPlanningActing2016}. The idea is to create rules for the computer to automatically search for an assembly task list. During a search, the computer can plan out when and how the clamps are moved, and whether it is necessary to place the clamp back to storage.

The implementation of automated task planning is developed and tested in the next Exploration Round \seerefii{subsection:exploration-5-tamp-with-pddlstream}{subsection:exploration-5-specifying-actions-and-goals-for-tamp-with-pddlstream}. The results showed that a large amount of clamp transfer does not need to go back to storage \seeref{subsubsection:exploration-5-optimised-clamp-transfer-tasks}.

\subsection{Difficulty in attaching beam to platform}
\label{subsection:exploration-3-difficulty-in-attaching-beam-to-platform}

The ground platform in this round was designed for accurate measurement of robotic precision. However, during construction, attaching the columns to the flat surface of the aluminium profile proved challenging (see Figure \ref{fig:column-resting-difficulty}). In many instances, a significant number of aluminium profiles were needed to provide a clamping surface between the column and the platform, as shown in Figure \ref{fig:temporary-scaffolding-needed-column-bottom}. These scaffolding elements are slow to erect, and their connection are not very stiff.

% 2 Horizontal Image
\begin{figure}[!h]
    \centering
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/6b/img16.jpg}
        \caption{Column resting on top of aluminium profile}
        \label{fig:column-resting-difficulty}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/6b/img17.jpg}
        \caption{Many temporary scaffolding elements needed to secure the column to the platform}
        \label{fig:temporary-scaffolding-needed-column-bottom}
    \end{subfigure}
    \caption{Photos showing the difficulty in attaching the column to the platform}
    \label{fig:column-attachment-difficulty}
\end{figure}

\paragraph{Possible Solution and Follow-Up}

The experience from constructing the BusStop pavilion indicated that it would be beneficial if the first few elements could be anchored to the platform with more than one connection. In order to achieve this, the design of the structure has to allow for this. This concept was tested when designing the next two demonstrators and was found to improve the stability substantially.

\subsection{Difficult to Plan Targets}
\label{subsection:exploration-3-difficult-to-plan-targets}

The chart below \parencite{huangNewAnalogProtocol2021} shows the planning time for each of the 40 beams in the BusStop using the MMMP solver developed in the previous section \seeref{subsection:exploration-3-non-sequential-planning-order}. Notice that two beams were particularly difficult to plan and took substantially longer time.

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.99\textwidth]{images/6b/img18.jpg}
    \caption{Chart showing the planning time for each of the 40 beams in the BusStop}
    \label{fig:planning-time-for-each-beam}
\end{figure}

The images below illustrate the problem of the difficulty faced at sequence 14. Figure \ref{fig:difficult-target-at-sequence-14} depict the moment (in different viewing angles) where the gripper (blue) holding the active beam (white) is approaching the clamp jaws (green). Notice that the free motion that brings the beam to this target had to slide through a narrow passage \seeref{subsection:exploration-2-narrow-passage-problem}. This is because the beam is blocked by the clamp jaws on one side, and blocked by one protruding portion of the already-assembled beams (light blue) on the other side.

% 2 Horizontal Image
\begin{figure}[!h]
    \centering
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/6b/img19.jpg}
        % \caption{SubFigureCaption}
        %\label{fig:uniquesubfigurelabel}
    \end{subfigure}
    \hfill
    \begin{subfigure}[b]{0.49\textwidth}
        \centering
        \includegraphics[width=\textwidth]{images/6b/img20.jpg}
        % \caption{SubFigureCaption}
        %\label{fig:uniquesubfigurelabel}
    \end{subfigure}
    \caption{Two different views of the difficult target at sequence 14}
    \label{fig:difficult-target-at-sequence-14}
\end{figure}


It was found that difficult problems like these are difficult to anticipate during assembly design and even during the process design phase. This is because:

\begin{itemize}
	\item The targets for the beam (particularly for this motion) depend on the orientation of the clamps. This is not known in the Assemble Design Phase.

	\item This is a valid target where no objects are in a collision. Therefore it will not be flagged by collision detection as an impossible target \seeref{subsection:exploration-2-checking-incorrect-planning-inputs}.

	\item Visual inspection by the process engineer during the Process Design Phase may miss the problem. Notice that the narrow passage is not obvious from the viewing angle in the left image above. Narrow passages may only become obvious in certain viewing angles, such as the image on the right.

\end{itemize}
Therefore, it is only during final planning that the difficulty is encountered. The long task list for each beam also made the difficult problem difficult to diagnose, often required reading log files to understand which motions failed most frequently. In later development, the task list was split into smaller chunks, which enabled easier diagnosis \seeref{subsection:exploration-4-planning-order-by-motion-group}.

\subsection{RFL Robot Inaccuracy and Calibration}
\label{subsection:exploration-3-rfl-robot-inaccuracy-and-calibration}

After many observations regarding substantial misalignment, I speculated that the RFL Robot is not properly calibrated, causing the motion planner to give inaccurate results. The observations include:

\begin{itemize}
	\item Misalignment between a robotically-placed beam and the ground platform \seeref{subsection:exploration-3-beam-placement-misalignment}.

	\item Misalignment between the joints on a robotically-placed beam and the partially assembled structure \seeref{subsection:exploration-3-beam-placement-misalignment}.

	\item Misalignment between the robot-side docking adapter and the tool-side adapter on clamps that are hanging on the structure \seeref{subsection:exploration-3-docking-adapter-misalignment}.

	\item Disagreement between the measured position of the clamps in storage (using iGPS) and the FK result based on the taught configuration.

\end{itemize}
A measurement was performed to observe the following alignment:

\begin{itemize}
	\item Straightness of gantry X Y Z axis
	\item Perpendicularity between X and Y axis of the gantry
	\item Perpendicularity between the Z axis of the gantry and the XY plane
	\item Parallelism between the Robot Arm Base and the XY plane of the gantry
	\item Alignment of the Robot Base X Direction (Joint 1 at zero) and the Gantry X axis
\end{itemize}

This measurement was performed by moving one axis at a time and measuring the end effector location using the iGPS system. This measurement was only performed sparsely in the middle of the working area, the result is not representative of the whole system. Figure \ref{fig:points-measured-by-the-igps} shows the measured points in the workspace.

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.99\textwidth]{images/6b/img21.jpg}
    \caption{Points measured by the iGPS system for the robot calibration}
    \label{fig:points-measured-by-the-igps}
\end{figure}

The analysed results are:

\begin{itemize}
	\item Gantry X-axis straightness: 0.52mm average deviation from a line fit.

	\item Gantry Y-axis straightness: 0.35mm average deviation from a line fit.

	\item Gantry Z-axis straightness: 0.15mm average deviation from a line fit.

	\item Perpendicularity between X-axis and Y-axis of the gantry: 90.002683 degrees.

	\item Perpendicularity between Gantry Z-axis and (XY Plane): 0.086004 degrees.

	\item Parallelism between the Robot Arm Base and the XY plane of the gantry is insignificant after considering the Z axis is tilted.

	\item Alignment of the Robot Base X Direction 0.019481 degrees.

\end{itemize}
In addition, the Z axis is found to sway from side to side, mostly along the XZ plane of the gantry) and the angle depends on the pose of the robotic arm underneath. This is likely the result of the stiffness of the Z-axis telescopic linear axis. Figure \ref{fig:z-axis-swaying-error} shows an exaggerated illustration of the error in the perpendicularity of Z-axis. The green outline shows the ideal Z-axis position, and the red line shows the swayed z-axis, causing the robotic arm to be tilted.

\begin{figure}[!h]
    \centering
    \includegraphics[width=0.99\textwidth]{images/6b/img22.jpg}
    \caption{Illustration of the Z-axis swaying error in the RFL Robot}
    \label{fig:z-axis-swaying-error}
\end{figure}

\FloatBarrier

The following joints in the URDF model were updated:

\begin{itemize}
	\item The Gantry Z-axis orientation (an average value of the swaying angle was used)
	\item The Position and orientation of the fixed joint between the Robotic Arm Base and the bottom of the Gantry Z axis
\end{itemize}

A comparison between measured values and the FK result shows that the average error is reduced from 6.46mm to 2.45mm after the URDF is adjusted. The remaining error is likely due to the nonlinear effects and dynamic deformation of the robotic system. These effects cannot be accommodated with the URDF model.

This URDF is used in the subsequent development rounds together with other measures for improving alignment accuracy. The combined effect resulted in an improvement in alignment. However, it is difficult to conclude which effect contributed the most.
